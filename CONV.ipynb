{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "import sys\n",
    "\n",
    "# !{sys.executable} -m pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read in datasets\n",
    "trainData = pd.read_csv(\"./Dataset/mnist_train.csv\", header=None)\n",
    "testData = pd.read_csv(\"./Dataset/mnist_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and Y data\n",
    "yTrain = {'Y': trainData[0]}\n",
    "yTrain = pd.DataFrame(yTrain)\n",
    "del trainData[0]\n",
    "\n",
    "yTest = {'Y': testData[0]}\n",
    "yTest = pd.DataFrame(yTest)\n",
    "del testData[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y\n",
       "1    6742\n",
       "7    6265\n",
       "3    6131\n",
       "2    5958\n",
       "9    5949\n",
       "0    5923\n",
       "6    5918\n",
       "8    5851\n",
       "4    5842\n",
       "5    5421\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training digit count\n",
    "display(yTrain.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test and Train Dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# create custom dataset\n",
    "class createDataset():\n",
    "    def __init__(self, images, numbers, transform=None):\n",
    "        self.images = images\n",
    "        self.numbers = numbers\n",
    "        # Store the transform to apply to the data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images.iloc[idx].values\n",
    "        number =self.numbers.iloc[idx].values\n",
    "\n",
    "        # nromalize image\n",
    "        # image = image/ 255\n",
    "\n",
    "     \n",
    "        # image = np.pad(image,pad_width=2)\n",
    "\n",
    "        # Apply the transform to the image, if specified\n",
    "        if self.transform:\n",
    "            # reshape image for transformation\n",
    "            image = np.reshape(image,[28,28])\n",
    "\n",
    "            # convert numpy array to PIL image\n",
    "            image = Image.fromarray((image).astype(np.uint8))\n",
    "            # display(image)\n",
    "            # perform transformation on the image\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # reshape image for transformation\n",
    "            image = np.reshape(image,[1,28,28])\n",
    "        return image, number\n",
    "\n",
    "# trainDataset = createDataset(trainData,yTrain)\n",
    "testDataset = createDataset(testData,yTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the dataset (adds robustness and increases training data)\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# function to add guassain noise to the images\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "# Create the transformations\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(degrees=2),\n",
    "    transforms.ToTensor(),\n",
    "    # AddGaussianNoise(0.,1.)\n",
    "])\n",
    "\n",
    "# Apply the transformations to the dataset\n",
    "trainaugmented = createDataset(trainData,yTrain, transform = train_transform)\n",
    "# trainaugmented = createDataset(trainData,yTrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7UlEQVR4nGNgGDaAEYXnXcpwmuHMSizqOJsXff339+/fvwmYcupz/v79+//jjo9/n2PIab/6+3f5wmRVBrXXmJJ3//29p8zAwMDQ+RtDMu7fvw4GBgYG/u5//17ABFmg9P//PzczMIhF5ir+Z/iPrjP27789aTtv/Lt9+u/fyeiS1hBfnJn/8e/fEgwHef37+/fvCXvLv3//2mP6k8E7lIGBQf/fvy64CAtCcisDAwOD13+G11g0QsCiv3/FccmJvP3bzoJLsvHvXz0EjwlVkovx9nOckgz/H7zGLcmwhgG35IaVeCTXf8bhVAwAAMQmYh5/3re5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "# Create DataLoader for train, validation and testing\n",
    "batchSize = 32\n",
    "trainloader = DataLoader(trainaugmented,batch_size=100,shuffle=True)\n",
    "testloader = DataLoader(testDataset, batch_size=1)\n",
    "\n",
    "# size of neural network input\n",
    "inputSize = len(trainData.sample().values[0])\n",
    "\n",
    "# num of classes\n",
    "numClasses =  len(yTrain['Y'].unique())\n",
    "\n",
    "# shape of the input image\n",
    "print(next(iter(trainloader))[0].shape)\n",
    "\n",
    "# display image\n",
    "image = next(iter(trainloader))[0]\n",
    "pil_img = torchvision.transforms.ToPILImage()(image.select(0,0))\n",
    "display(pil_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of numberPrediction(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: False\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Network\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class numberPrediction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(numberPrediction, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "   \n",
    "        return\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)   \n",
    "\n",
    "\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n",
    "\n",
    "# create and print model\n",
    "predictionModel = numberPrediction()\n",
    "print(predictionModel.parameters)\n",
    "\n",
    "\n",
    "# Declaring Criterion and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "criterion\n",
    "\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(predictionModel.parameters(), lr = 0.01)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     0] loss: 230.777, speed: 25.00, accuracy: 7.00 %\n",
      "[1,    10] loss: 2473.100, speed: 26.13, accuracy: 23.91 %\n",
      "[1,    20] loss: 3438.499, speed: 26.85, accuracy: 48.43 %\n",
      "[1,    30] loss: 3904.823, speed: 26.75, accuracy: 61.39 %\n",
      "[1,    40] loss: 4194.354, speed: 26.78, accuracy: 68.46 %\n",
      "[1,    50] loss: 4390.566, speed: 26.80, accuracy: 73.55 %\n",
      "[1,    60] loss: 4597.311, speed: 26.88, accuracy: 77.03 %\n",
      "[1,    70] loss: 4807.598, speed: 26.89, accuracy: 79.45 %\n",
      "[1,    80] loss: 4971.252, speed: 26.98, accuracy: 81.38 %\n",
      "[1,    90] loss: 5152.595, speed: 27.00, accuracy: 82.80 %\n",
      "[1,   100] loss: 5393.257, speed: 27.02, accuracy: 83.75 %\n",
      "[1,   110] loss: 5566.100, speed: 26.97, accuracy: 84.66 %\n",
      "[1,   120] loss: 5752.771, speed: 27.00, accuracy: 85.49 %\n",
      "[1,   130] loss: 5884.563, speed: 27.04, accuracy: 86.23 %\n",
      "[1,   140] loss: 6043.519, speed: 27.11, accuracy: 86.85 %\n",
      "[1,   150] loss: 6177.915, speed: 27.17, accuracy: 87.44 %\n",
      "[1,   160] loss: 6292.498, speed: 27.14, accuracy: 87.99 %\n",
      "[1,   170] loss: 6426.812, speed: 27.13, accuracy: 88.43 %\n",
      "[1,   180] loss: 6556.277, speed: 27.15, accuracy: 88.87 %\n",
      "[1,   190] loss: 6701.496, speed: 27.14, accuracy: 89.23 %\n",
      "[1,   200] loss: 6815.362, speed: 27.14, accuracy: 89.60 %\n",
      "[1,   210] loss: 6935.830, speed: 27.15, accuracy: 89.91 %\n",
      "[1,   220] loss: 7042.966, speed: 27.15, accuracy: 90.21 %\n",
      "[1,   230] loss: 7160.612, speed: 27.17, accuracy: 90.47 %\n",
      "[1,   240] loss: 7308.639, speed: 27.17, accuracy: 90.69 %\n",
      "[1,   250] loss: 7451.137, speed: 27.19, accuracy: 90.90 %\n",
      "[1,   260] loss: 7554.767, speed: 27.16, accuracy: 91.13 %\n",
      "[1,   270] loss: 7660.115, speed: 27.17, accuracy: 91.34 %\n",
      "[1,   280] loss: 7798.890, speed: 27.13, accuracy: 91.49 %\n",
      "[1,   290] loss: 7920.176, speed: 27.11, accuracy: 91.66 %\n",
      "[1,   300] loss: 8029.437, speed: 27.15, accuracy: 91.79 %\n",
      "[1,   310] loss: 8160.629, speed: 27.17, accuracy: 91.94 %\n",
      "[1,   320] loss: 8273.614, speed: 27.20, accuracy: 92.07 %\n",
      "[1,   330] loss: 8383.017, speed: 27.22, accuracy: 92.21 %\n",
      "[1,   340] loss: 8519.596, speed: 27.21, accuracy: 92.33 %\n",
      "[1,   350] loss: 8616.074, speed: 27.24, accuracy: 92.46 %\n",
      "[1,   360] loss: 8720.024, speed: 27.25, accuracy: 92.56 %\n",
      "[1,   370] loss: 8833.103, speed: 27.27, accuracy: 92.67 %\n",
      "[1,   380] loss: 8928.081, speed: 27.29, accuracy: 92.79 %\n",
      "[1,   390] loss: 9029.123, speed: 27.32, accuracy: 92.88 %\n",
      "[1,   400] loss: 9161.295, speed: 27.33, accuracy: 92.97 %\n",
      "[1,   410] loss: 9283.665, speed: 27.32, accuracy: 93.05 %\n",
      "[1,   420] loss: 9385.818, speed: 27.33, accuracy: 93.12 %\n",
      "[1,   430] loss: 9492.991, speed: 27.33, accuracy: 93.19 %\n",
      "[1,   440] loss: 9598.533, speed: 27.32, accuracy: 93.27 %\n",
      "[1,   450] loss: 9691.743, speed: 27.31, accuracy: 93.35 %\n",
      "[1,   460] loss: 9787.240, speed: 27.30, accuracy: 93.44 %\n",
      "[1,   470] loss: 9896.309, speed: 27.31, accuracy: 93.51 %\n",
      "[1,   480] loss: 10032.590, speed: 27.32, accuracy: 93.56 %\n",
      "[1,   490] loss: 10118.721, speed: 27.34, accuracy: 93.63 %\n",
      "[1,   500] loss: 10232.124, speed: 27.34, accuracy: 93.69 %\n",
      "[1,   510] loss: 10312.315, speed: 27.34, accuracy: 93.76 %\n",
      "[1,   520] loss: 10452.667, speed: 27.36, accuracy: 93.79 %\n",
      "[1,   530] loss: 10521.160, speed: 27.38, accuracy: 93.87 %\n",
      "[1,   540] loss: 10586.280, speed: 27.38, accuracy: 93.94 %\n",
      "[1,   550] loss: 10666.127, speed: 27.39, accuracy: 94.00 %\n",
      "[1,   560] loss: 10747.715, speed: 27.40, accuracy: 94.06 %\n",
      "[1,   570] loss: 10801.580, speed: 27.39, accuracy: 94.14 %\n",
      "[1,   580] loss: 10897.421, speed: 27.40, accuracy: 94.19 %\n",
      "[1,   590] loss: 10961.663, speed: 27.40, accuracy: 94.25 %\n",
      "[2,     0] loss: 10.500, speed: 27.77, accuracy: 96.00 %\n",
      "[2,    10] loss: 71.429, speed: 27.99, accuracy: 97.55 %\n",
      "[2,    20] loss: 134.935, speed: 27.63, accuracy: 97.76 %\n",
      "[2,    30] loss: 209.951, speed: 27.68, accuracy: 97.74 %\n",
      "[2,    40] loss: 320.149, speed: 27.85, accuracy: 97.54 %\n",
      "[2,    50] loss: 419.660, speed: 27.82, accuracy: 97.57 %\n",
      "[2,    60] loss: 494.183, speed: 27.75, accuracy: 97.59 %\n",
      "[2,    70] loss: 574.193, speed: 27.78, accuracy: 97.62 %\n",
      "[2,    80] loss: 632.665, speed: 27.83, accuracy: 97.67 %\n",
      "[2,    90] loss: 704.763, speed: 27.85, accuracy: 97.68 %\n",
      "[2,   100] loss: 790.095, speed: 27.86, accuracy: 97.66 %\n",
      "[2,   110] loss: 891.153, speed: 27.86, accuracy: 97.58 %\n",
      "[2,   120] loss: 956.994, speed: 27.88, accuracy: 97.65 %\n",
      "[2,   130] loss: 1034.547, speed: 27.85, accuracy: 97.66 %\n",
      "[2,   140] loss: 1087.187, speed: 27.84, accuracy: 97.72 %\n",
      "[2,   150] loss: 1171.761, speed: 27.82, accuracy: 97.65 %\n",
      "[2,   160] loss: 1315.313, speed: 27.84, accuracy: 97.59 %\n",
      "[2,   170] loss: 1394.842, speed: 27.85, accuracy: 97.58 %\n",
      "[2,   180] loss: 1461.488, speed: 27.85, accuracy: 97.62 %\n",
      "[2,   190] loss: 1526.691, speed: 27.83, accuracy: 97.65 %\n",
      "[2,   200] loss: 1627.860, speed: 27.79, accuracy: 97.61 %\n",
      "[2,   210] loss: 1726.487, speed: 27.77, accuracy: 97.55 %\n",
      "[2,   220] loss: 1830.793, speed: 27.76, accuracy: 97.55 %\n",
      "[2,   230] loss: 1963.683, speed: 27.76, accuracy: 97.48 %\n",
      "[2,   240] loss: 2046.220, speed: 27.70, accuracy: 97.50 %\n",
      "[2,   250] loss: 2111.281, speed: 27.70, accuracy: 97.53 %\n",
      "[2,   260] loss: 2194.282, speed: 27.69, accuracy: 97.54 %\n",
      "[2,   270] loss: 2274.112, speed: 27.66, accuracy: 97.55 %\n",
      "[2,   280] loss: 2361.478, speed: 27.64, accuracy: 97.52 %\n",
      "[2,   290] loss: 2478.504, speed: 27.64, accuracy: 97.47 %\n",
      "[2,   300] loss: 2558.182, speed: 27.62, accuracy: 97.48 %\n",
      "[2,   310] loss: 2633.858, speed: 27.61, accuracy: 97.48 %\n",
      "[2,   320] loss: 2714.120, speed: 27.54, accuracy: 97.49 %\n",
      "[2,   330] loss: 2760.620, speed: 27.53, accuracy: 97.52 %\n",
      "[2,   340] loss: 2836.580, speed: 27.50, accuracy: 97.54 %\n",
      "[2,   350] loss: 2923.731, speed: 27.52, accuracy: 97.52 %\n",
      "[2,   360] loss: 2993.484, speed: 27.51, accuracy: 97.53 %\n",
      "[2,   370] loss: 3044.194, speed: 27.50, accuracy: 97.56 %\n",
      "[2,   380] loss: 3116.063, speed: 27.47, accuracy: 97.54 %\n",
      "[2,   390] loss: 3169.656, speed: 27.48, accuracy: 97.56 %\n",
      "[2,   400] loss: 3239.316, speed: 27.48, accuracy: 97.56 %\n",
      "[2,   410] loss: 3333.684, speed: 27.48, accuracy: 97.56 %\n",
      "[2,   420] loss: 3434.113, speed: 27.48, accuracy: 97.54 %\n",
      "[2,   430] loss: 3478.382, speed: 27.46, accuracy: 97.55 %\n",
      "[2,   440] loss: 3545.618, speed: 27.45, accuracy: 97.55 %\n",
      "[2,   450] loss: 3648.904, speed: 27.45, accuracy: 97.53 %\n",
      "[2,   460] loss: 3738.740, speed: 27.44, accuracy: 97.52 %\n",
      "[2,   470] loss: 3813.462, speed: 27.44, accuracy: 97.52 %\n",
      "[2,   480] loss: 3871.397, speed: 27.44, accuracy: 97.53 %\n",
      "[2,   490] loss: 3987.759, speed: 27.45, accuracy: 97.52 %\n",
      "[2,   500] loss: 4075.240, speed: 27.43, accuracy: 97.51 %\n",
      "[2,   510] loss: 4162.587, speed: 27.43, accuracy: 97.50 %\n",
      "[2,   520] loss: 4231.186, speed: 27.44, accuracy: 97.51 %\n",
      "[2,   530] loss: 4283.840, speed: 27.45, accuracy: 97.53 %\n",
      "[2,   540] loss: 4355.049, speed: 27.44, accuracy: 97.54 %\n",
      "[2,   550] loss: 4428.504, speed: 27.44, accuracy: 97.54 %\n",
      "[2,   560] loss: 4504.782, speed: 27.42, accuracy: 97.54 %\n",
      "[2,   570] loss: 4581.425, speed: 27.41, accuracy: 97.54 %\n",
      "[2,   580] loss: 4650.658, speed: 27.42, accuracy: 97.55 %\n",
      "[2,   590] loss: 4734.105, speed: 27.44, accuracy: 97.55 %\n",
      "[3,     0] loss: 7.914, speed: 26.32, accuracy: 98.00 %\n",
      "[3,    10] loss: 88.921, speed: 27.09, accuracy: 97.45 %\n",
      "[3,    20] loss: 150.820, speed: 27.13, accuracy: 97.33 %\n",
      "[3,    30] loss: 222.734, speed: 26.79, accuracy: 97.52 %\n",
      "[3,    40] loss: 293.938, speed: 26.85, accuracy: 97.61 %\n",
      "[3,    50] loss: 359.009, speed: 27.03, accuracy: 97.67 %\n",
      "[3,    60] loss: 452.795, speed: 27.10, accuracy: 97.62 %\n",
      "[3,    70] loss: 557.808, speed: 27.17, accuracy: 97.51 %\n",
      "[3,    80] loss: 632.137, speed: 27.21, accuracy: 97.53 %\n",
      "[3,    90] loss: 709.185, speed: 27.28, accuracy: 97.59 %\n",
      "[3,   100] loss: 774.012, speed: 27.33, accuracy: 97.64 %\n",
      "[3,   110] loss: 836.387, speed: 27.39, accuracy: 97.72 %\n",
      "[3,   120] loss: 885.295, speed: 27.42, accuracy: 97.77 %\n",
      "[3,   130] loss: 939.661, speed: 27.45, accuracy: 97.78 %\n",
      "[3,   140] loss: 993.919, speed: 27.48, accuracy: 97.80 %\n",
      "[3,   150] loss: 1047.217, speed: 27.47, accuracy: 97.82 %\n",
      "[3,   160] loss: 1134.811, speed: 27.50, accuracy: 97.83 %\n",
      "[3,   170] loss: 1194.503, speed: 27.52, accuracy: 97.84 %\n",
      "[3,   180] loss: 1274.357, speed: 27.52, accuracy: 97.83 %\n",
      "[3,   190] loss: 1358.988, speed: 27.48, accuracy: 97.80 %\n",
      "[3,   200] loss: 1417.821, speed: 27.52, accuracy: 97.84 %\n",
      "[3,   210] loss: 1483.595, speed: 27.53, accuracy: 97.85 %\n",
      "[3,   220] loss: 1535.081, speed: 27.56, accuracy: 97.86 %\n",
      "[3,   230] loss: 1606.862, speed: 27.56, accuracy: 97.86 %\n",
      "[3,   240] loss: 1699.049, speed: 27.55, accuracy: 97.84 %\n",
      "[3,   250] loss: 1756.099, speed: 27.52, accuracy: 97.84 %\n",
      "[3,   260] loss: 1821.361, speed: 27.54, accuracy: 97.84 %\n",
      "[3,   270] loss: 1866.210, speed: 27.55, accuracy: 97.85 %\n",
      "[3,   280] loss: 1944.359, speed: 27.55, accuracy: 97.82 %\n",
      "[3,   290] loss: 1993.493, speed: 27.56, accuracy: 97.85 %\n",
      "[3,   300] loss: 2043.258, speed: 27.54, accuracy: 97.86 %\n",
      "[3,   310] loss: 2120.752, speed: 27.57, accuracy: 97.85 %\n",
      "[3,   320] loss: 2206.660, speed: 27.59, accuracy: 97.85 %\n",
      "[3,   330] loss: 2284.529, speed: 27.60, accuracy: 97.86 %\n",
      "[3,   340] loss: 2351.781, speed: 27.62, accuracy: 97.86 %\n",
      "[3,   350] loss: 2415.949, speed: 27.62, accuracy: 97.85 %\n",
      "[3,   360] loss: 2484.503, speed: 27.60, accuracy: 97.86 %\n",
      "[3,   370] loss: 2521.063, speed: 27.61, accuracy: 97.89 %\n",
      "[3,   380] loss: 2605.498, speed: 27.63, accuracy: 97.87 %\n",
      "[3,   390] loss: 2677.023, speed: 27.63, accuracy: 97.85 %\n",
      "[3,   400] loss: 2743.246, speed: 27.63, accuracy: 97.86 %\n",
      "[3,   410] loss: 2836.793, speed: 27.62, accuracy: 97.85 %\n",
      "[3,   420] loss: 2937.519, speed: 27.60, accuracy: 97.83 %\n",
      "[3,   430] loss: 2971.904, speed: 27.62, accuracy: 97.84 %\n",
      "[3,   440] loss: 3028.350, speed: 27.63, accuracy: 97.85 %\n",
      "[3,   450] loss: 3088.694, speed: 27.60, accuracy: 97.87 %\n",
      "[3,   460] loss: 3169.692, speed: 27.59, accuracy: 97.86 %\n",
      "[3,   470] loss: 3243.762, speed: 27.59, accuracy: 97.86 %\n",
      "[3,   480] loss: 3327.472, speed: 27.58, accuracy: 97.86 %\n",
      "[3,   490] loss: 3399.553, speed: 27.58, accuracy: 97.85 %\n",
      "[3,   500] loss: 3448.734, speed: 27.56, accuracy: 97.86 %\n",
      "[3,   510] loss: 3497.962, speed: 27.56, accuracy: 97.88 %\n",
      "[3,   520] loss: 3571.753, speed: 27.55, accuracy: 97.88 %\n",
      "[3,   530] loss: 3661.507, speed: 27.56, accuracy: 97.88 %\n",
      "[3,   540] loss: 3735.143, speed: 27.55, accuracy: 97.88 %\n",
      "[3,   550] loss: 3791.617, speed: 27.55, accuracy: 97.89 %\n",
      "[3,   560] loss: 3860.313, speed: 27.56, accuracy: 97.89 %\n",
      "[3,   570] loss: 3933.492, speed: 27.57, accuracy: 97.89 %\n",
      "[3,   580] loss: 3989.102, speed: 27.56, accuracy: 97.90 %\n",
      "[3,   590] loss: 4036.611, speed: 27.57, accuracy: 97.90 %\n",
      "[4,     0] loss: 6.804, speed: 28.57, accuracy: 97.00 %\n",
      "[4,    10] loss: 40.238, speed: 28.05, accuracy: 98.73 %\n",
      "[4,    20] loss: 109.781, speed: 27.96, accuracy: 98.38 %\n",
      "[4,    30] loss: 151.966, speed: 28.00, accuracy: 98.45 %\n",
      "[4,    40] loss: 208.537, speed: 27.81, accuracy: 98.37 %\n",
      "[4,    50] loss: 268.479, speed: 27.72, accuracy: 98.37 %\n",
      "[4,    60] loss: 328.544, speed: 27.65, accuracy: 98.36 %\n",
      "[4,    70] loss: 380.407, speed: 27.72, accuracy: 98.32 %\n",
      "[4,    80] loss: 455.181, speed: 27.66, accuracy: 98.28 %\n",
      "[4,    90] loss: 538.167, speed: 27.68, accuracy: 98.16 %\n",
      "[4,   100] loss: 568.219, speed: 27.72, accuracy: 98.23 %\n",
      "[4,   110] loss: 624.408, speed: 27.74, accuracy: 98.24 %\n",
      "[4,   120] loss: 654.537, speed: 27.71, accuracy: 98.29 %\n",
      "[4,   130] loss: 759.407, speed: 27.75, accuracy: 98.21 %\n",
      "[4,   140] loss: 837.443, speed: 27.71, accuracy: 98.16 %\n",
      "[4,   150] loss: 912.832, speed: 27.68, accuracy: 98.15 %\n",
      "[4,   160] loss: 977.041, speed: 27.74, accuracy: 98.14 %\n",
      "[4,   170] loss: 1034.264, speed: 27.75, accuracy: 98.15 %\n",
      "[4,   180] loss: 1094.004, speed: 27.73, accuracy: 98.14 %\n",
      "[4,   190] loss: 1155.463, speed: 27.72, accuracy: 98.13 %\n",
      "[4,   200] loss: 1203.405, speed: 27.74, accuracy: 98.11 %\n",
      "[4,   210] loss: 1243.366, speed: 27.73, accuracy: 98.14 %\n",
      "[4,   220] loss: 1294.657, speed: 27.77, accuracy: 98.15 %\n",
      "[4,   230] loss: 1346.527, speed: 27.75, accuracy: 98.16 %\n",
      "[4,   240] loss: 1400.665, speed: 27.75, accuracy: 98.16 %\n",
      "[4,   250] loss: 1451.839, speed: 27.73, accuracy: 98.19 %\n",
      "[4,   260] loss: 1551.418, speed: 27.72, accuracy: 98.15 %\n",
      "[4,   270] loss: 1602.301, speed: 27.71, accuracy: 98.15 %\n",
      "[4,   280] loss: 1684.094, speed: 27.71, accuracy: 98.14 %\n",
      "[4,   290] loss: 1723.547, speed: 27.70, accuracy: 98.16 %\n",
      "[4,   300] loss: 1795.325, speed: 27.69, accuracy: 98.15 %\n",
      "[4,   310] loss: 1892.678, speed: 27.70, accuracy: 98.13 %\n",
      "[4,   320] loss: 1960.206, speed: 27.71, accuracy: 98.12 %\n",
      "[4,   330] loss: 2013.448, speed: 27.68, accuracy: 98.13 %\n",
      "[4,   340] loss: 2078.431, speed: 27.69, accuracy: 98.12 %\n",
      "[4,   350] loss: 2140.293, speed: 27.71, accuracy: 98.10 %\n",
      "[4,   360] loss: 2219.221, speed: 27.68, accuracy: 98.09 %\n",
      "[4,   370] loss: 2307.673, speed: 27.70, accuracy: 98.07 %\n",
      "[4,   380] loss: 2368.280, speed: 27.69, accuracy: 98.08 %\n",
      "[4,   390] loss: 2431.548, speed: 27.69, accuracy: 98.08 %\n",
      "[4,   400] loss: 2499.321, speed: 27.69, accuracy: 98.07 %\n",
      "[4,   410] loss: 2545.089, speed: 27.67, accuracy: 98.10 %\n",
      "[4,   420] loss: 2601.834, speed: 27.68, accuracy: 98.11 %\n",
      "[4,   430] loss: 2690.300, speed: 27.67, accuracy: 98.10 %\n",
      "[4,   440] loss: 2762.626, speed: 27.69, accuracy: 98.10 %\n",
      "[4,   450] loss: 2849.391, speed: 27.70, accuracy: 98.10 %\n",
      "[4,   460] loss: 2901.288, speed: 27.71, accuracy: 98.10 %\n",
      "[4,   470] loss: 2963.365, speed: 27.72, accuracy: 98.10 %\n",
      "[4,   480] loss: 3017.912, speed: 27.73, accuracy: 98.10 %\n",
      "[4,   490] loss: 3076.139, speed: 27.72, accuracy: 98.08 %\n",
      "[4,   500] loss: 3120.548, speed: 27.73, accuracy: 98.09 %\n",
      "[4,   510] loss: 3183.094, speed: 27.75, accuracy: 98.08 %\n",
      "[4,   520] loss: 3262.819, speed: 27.73, accuracy: 98.07 %\n",
      "[4,   530] loss: 3354.946, speed: 27.71, accuracy: 98.06 %\n",
      "[4,   540] loss: 3429.355, speed: 27.71, accuracy: 98.05 %\n",
      "[4,   550] loss: 3512.875, speed: 27.70, accuracy: 98.05 %\n",
      "[4,   560] loss: 3591.260, speed: 27.70, accuracy: 98.04 %\n",
      "[4,   570] loss: 3675.736, speed: 27.69, accuracy: 98.04 %\n",
      "[4,   580] loss: 3730.740, speed: 27.69, accuracy: 98.05 %\n",
      "[4,   590] loss: 3832.048, speed: 27.69, accuracy: 98.04 %\n",
      "[5,     0] loss: 3.252, speed: 27.78, accuracy: 98.00 %\n",
      "[5,    10] loss: 66.486, speed: 27.92, accuracy: 97.64 %\n",
      "[5,    20] loss: 112.987, speed: 27.93, accuracy: 98.00 %\n",
      "[5,    30] loss: 191.761, speed: 27.85, accuracy: 97.97 %\n",
      "[5,    40] loss: 242.965, speed: 27.82, accuracy: 98.07 %\n",
      "[5,    50] loss: 302.359, speed: 27.73, accuracy: 97.96 %\n",
      "[5,    60] loss: 349.879, speed: 27.82, accuracy: 98.07 %\n",
      "[5,    70] loss: 415.351, speed: 27.80, accuracy: 98.04 %\n",
      "[5,    80] loss: 477.203, speed: 27.87, accuracy: 98.02 %\n",
      "[5,    90] loss: 531.923, speed: 27.85, accuracy: 98.04 %\n",
      "[5,   100] loss: 566.521, speed: 27.80, accuracy: 98.10 %\n",
      "[5,   110] loss: 602.016, speed: 27.83, accuracy: 98.18 %\n",
      "[5,   120] loss: 662.742, speed: 27.77, accuracy: 98.17 %\n",
      "[5,   130] loss: 719.945, speed: 27.76, accuracy: 98.17 %\n",
      "[5,   140] loss: 781.997, speed: 27.75, accuracy: 98.15 %\n",
      "[5,   150] loss: 837.136, speed: 27.78, accuracy: 98.16 %\n",
      "[5,   160] loss: 889.791, speed: 27.78, accuracy: 98.15 %\n",
      "[5,   170] loss: 975.118, speed: 27.78, accuracy: 98.14 %\n",
      "[5,   180] loss: 1061.306, speed: 27.75, accuracy: 98.13 %\n",
      "[5,   190] loss: 1104.358, speed: 27.73, accuracy: 98.16 %\n",
      "[5,   200] loss: 1174.284, speed: 27.75, accuracy: 98.16 %\n",
      "[5,   210] loss: 1211.367, speed: 27.77, accuracy: 98.19 %\n",
      "[5,   220] loss: 1255.593, speed: 27.72, accuracy: 98.23 %\n",
      "[5,   230] loss: 1320.742, speed: 27.73, accuracy: 98.23 %\n",
      "[5,   240] loss: 1375.340, speed: 27.75, accuracy: 98.22 %\n",
      "[5,   250] loss: 1435.224, speed: 27.77, accuracy: 98.22 %\n",
      "[5,   260] loss: 1503.899, speed: 27.77, accuracy: 98.23 %\n",
      "[5,   270] loss: 1551.786, speed: 27.77, accuracy: 98.25 %\n",
      "[5,   280] loss: 1603.103, speed: 27.75, accuracy: 98.25 %\n",
      "[5,   290] loss: 1681.041, speed: 27.74, accuracy: 98.23 %\n",
      "[5,   300] loss: 1749.934, speed: 27.74, accuracy: 98.22 %\n",
      "[5,   310] loss: 1803.426, speed: 27.73, accuracy: 98.23 %\n",
      "[5,   320] loss: 1872.407, speed: 27.75, accuracy: 98.24 %\n",
      "[5,   330] loss: 1954.764, speed: 27.75, accuracy: 98.22 %\n",
      "[5,   340] loss: 2007.751, speed: 27.75, accuracy: 98.23 %\n",
      "[5,   350] loss: 2077.050, speed: 27.73, accuracy: 98.22 %\n",
      "[5,   360] loss: 2116.693, speed: 27.72, accuracy: 98.23 %\n",
      "[5,   370] loss: 2174.115, speed: 27.71, accuracy: 98.23 %\n",
      "[5,   380] loss: 2244.840, speed: 27.73, accuracy: 98.22 %\n",
      "[5,   390] loss: 2315.026, speed: 27.70, accuracy: 98.22 %\n",
      "[5,   400] loss: 2386.413, speed: 27.70, accuracy: 98.21 %\n",
      "[5,   410] loss: 2469.501, speed: 27.70, accuracy: 98.22 %\n",
      "[5,   420] loss: 2518.043, speed: 27.69, accuracy: 98.24 %\n",
      "[5,   430] loss: 2603.697, speed: 27.71, accuracy: 98.23 %\n",
      "[5,   440] loss: 2667.117, speed: 27.72, accuracy: 98.21 %\n",
      "[5,   450] loss: 2715.448, speed: 27.70, accuracy: 98.20 %\n",
      "[5,   460] loss: 2782.712, speed: 27.71, accuracy: 98.21 %\n",
      "[5,   470] loss: 2855.651, speed: 27.70, accuracy: 98.20 %\n",
      "[5,   480] loss: 2929.893, speed: 27.69, accuracy: 98.19 %\n",
      "[5,   490] loss: 3010.568, speed: 27.69, accuracy: 98.19 %\n",
      "[5,   500] loss: 3053.931, speed: 27.70, accuracy: 98.20 %\n",
      "[5,   510] loss: 3102.828, speed: 27.69, accuracy: 98.21 %\n",
      "[5,   520] loss: 3148.657, speed: 27.70, accuracy: 98.21 %\n",
      "[5,   530] loss: 3212.532, speed: 27.71, accuracy: 98.22 %\n",
      "[5,   540] loss: 3288.083, speed: 27.71, accuracy: 98.20 %\n",
      "[5,   550] loss: 3363.209, speed: 27.71, accuracy: 98.19 %\n",
      "[5,   560] loss: 3448.084, speed: 27.71, accuracy: 98.18 %\n",
      "[5,   570] loss: 3506.314, speed: 27.70, accuracy: 98.18 %\n",
      "[5,   580] loss: 3550.863, speed: 27.71, accuracy: 98.18 %\n",
      "[5,   590] loss: 3609.202, speed: 27.72, accuracy: 98.19 %\n",
      "[6,     0] loss: 4.945, speed: 27.78, accuracy: 97.00 %\n",
      "[6,    10] loss: 41.140, speed: 27.36, accuracy: 98.82 %\n",
      "[6,    20] loss: 93.180, speed: 27.34, accuracy: 98.86 %\n",
      "[6,    30] loss: 157.773, speed: 27.40, accuracy: 98.77 %\n",
      "[6,    40] loss: 194.425, speed: 27.42, accuracy: 98.71 %\n",
      "[6,    50] loss: 243.544, speed: 27.47, accuracy: 98.71 %\n",
      "[6,    60] loss: 277.238, speed: 27.57, accuracy: 98.74 %\n",
      "[6,    70] loss: 329.016, speed: 27.60, accuracy: 98.76 %\n",
      "[6,    80] loss: 361.778, speed: 27.63, accuracy: 98.78 %\n",
      "[6,    90] loss: 420.371, speed: 27.61, accuracy: 98.80 %\n",
      "[6,   100] loss: 477.798, speed: 27.62, accuracy: 98.76 %\n",
      "[6,   110] loss: 522.369, speed: 27.56, accuracy: 98.78 %\n",
      "[6,   120] loss: 555.511, speed: 27.55, accuracy: 98.80 %\n",
      "[6,   130] loss: 594.987, speed: 27.59, accuracy: 98.78 %\n",
      "[6,   140] loss: 664.123, speed: 27.56, accuracy: 98.72 %\n",
      "[6,   150] loss: 717.069, speed: 27.54, accuracy: 98.72 %\n",
      "[6,   160] loss: 782.212, speed: 27.55, accuracy: 98.70 %\n",
      "[6,   170] loss: 828.169, speed: 27.57, accuracy: 98.70 %\n",
      "[6,   180] loss: 877.350, speed: 27.57, accuracy: 98.66 %\n",
      "[6,   190] loss: 926.876, speed: 27.57, accuracy: 98.65 %\n",
      "[6,   200] loss: 979.065, speed: 27.57, accuracy: 98.63 %\n",
      "[6,   210] loss: 1049.918, speed: 27.56, accuracy: 98.57 %\n",
      "[6,   220] loss: 1092.415, speed: 27.56, accuracy: 98.57 %\n",
      "[6,   230] loss: 1174.916, speed: 27.55, accuracy: 98.54 %\n",
      "[6,   240] loss: 1242.657, speed: 27.54, accuracy: 98.52 %\n",
      "[6,   250] loss: 1307.674, speed: 27.53, accuracy: 98.51 %\n",
      "[6,   260] loss: 1375.545, speed: 27.53, accuracy: 98.51 %\n",
      "[6,   270] loss: 1450.154, speed: 27.54, accuracy: 98.47 %\n",
      "[6,   280] loss: 1525.058, speed: 27.52, accuracy: 98.45 %\n",
      "[6,   290] loss: 1582.511, speed: 27.51, accuracy: 98.43 %\n",
      "[6,   300] loss: 1644.323, speed: 27.51, accuracy: 98.41 %\n",
      "[6,   310] loss: 1707.900, speed: 27.52, accuracy: 98.39 %\n",
      "[6,   320] loss: 1771.380, speed: 27.52, accuracy: 98.37 %\n",
      "[6,   330] loss: 1823.847, speed: 27.53, accuracy: 98.37 %\n",
      "[6,   340] loss: 1899.781, speed: 27.55, accuracy: 98.35 %\n",
      "[6,   350] loss: 2012.008, speed: 27.54, accuracy: 98.32 %\n",
      "[6,   360] loss: 2098.873, speed: 27.54, accuracy: 98.30 %\n",
      "[6,   370] loss: 2170.996, speed: 27.54, accuracy: 98.30 %\n",
      "[6,   380] loss: 2244.865, speed: 27.53, accuracy: 98.29 %\n",
      "[6,   390] loss: 2311.895, speed: 27.54, accuracy: 98.28 %\n",
      "[6,   400] loss: 2365.448, speed: 27.55, accuracy: 98.28 %\n",
      "[6,   410] loss: 2419.348, speed: 27.56, accuracy: 98.28 %\n",
      "[6,   420] loss: 2503.435, speed: 27.54, accuracy: 98.28 %\n",
      "[6,   430] loss: 2569.680, speed: 27.54, accuracy: 98.27 %\n",
      "[6,   440] loss: 2612.421, speed: 27.53, accuracy: 98.28 %\n",
      "[6,   450] loss: 2672.693, speed: 27.53, accuracy: 98.27 %\n",
      "[6,   460] loss: 2743.371, speed: 27.52, accuracy: 98.26 %\n",
      "[6,   470] loss: 2810.646, speed: 27.50, accuracy: 98.27 %\n",
      "[6,   480] loss: 2852.795, speed: 27.50, accuracy: 98.27 %\n",
      "[6,   490] loss: 2907.048, speed: 27.49, accuracy: 98.28 %\n",
      "[6,   500] loss: 2950.815, speed: 27.50, accuracy: 98.29 %\n",
      "[6,   510] loss: 2999.226, speed: 27.50, accuracy: 98.29 %\n",
      "[6,   520] loss: 3074.873, speed: 27.50, accuracy: 98.29 %\n",
      "[6,   530] loss: 3143.767, speed: 27.51, accuracy: 98.28 %\n",
      "[6,   540] loss: 3210.653, speed: 27.50, accuracy: 98.27 %\n",
      "[6,   550] loss: 3265.933, speed: 27.50, accuracy: 98.28 %\n",
      "[6,   560] loss: 3318.122, speed: 27.51, accuracy: 98.27 %\n",
      "[6,   570] loss: 3359.713, speed: 27.51, accuracy: 98.27 %\n",
      "[6,   580] loss: 3422.997, speed: 27.51, accuracy: 98.26 %\n",
      "[6,   590] loss: 3499.004, speed: 27.52, accuracy: 98.26 %\n",
      "[7,     0] loss: 7.663, speed: 27.02, accuracy: 97.00 %\n",
      "[7,    10] loss: 58.354, speed: 27.92, accuracy: 98.36 %\n",
      "[7,    20] loss: 115.393, speed: 27.74, accuracy: 98.24 %\n",
      "[7,    30] loss: 165.828, speed: 27.88, accuracy: 98.32 %\n",
      "[7,    40] loss: 213.094, speed: 27.67, accuracy: 98.39 %\n",
      "[7,    50] loss: 260.757, speed: 27.57, accuracy: 98.43 %\n",
      "[7,    60] loss: 314.316, speed: 27.74, accuracy: 98.46 %\n",
      "[7,    70] loss: 382.264, speed: 27.59, accuracy: 98.38 %\n",
      "[7,    80] loss: 432.535, speed: 27.55, accuracy: 98.30 %\n",
      "[7,    90] loss: 520.067, speed: 27.58, accuracy: 98.19 %\n",
      "[7,   100] loss: 623.060, speed: 27.54, accuracy: 98.14 %\n",
      "[7,   110] loss: 698.515, speed: 27.63, accuracy: 98.12 %\n",
      "[7,   120] loss: 769.715, speed: 27.66, accuracy: 98.09 %\n",
      "[7,   130] loss: 801.990, speed: 27.65, accuracy: 98.15 %\n",
      "[7,   140] loss: 882.897, speed: 27.66, accuracy: 98.13 %\n",
      "[7,   150] loss: 948.223, speed: 27.69, accuracy: 98.12 %\n",
      "[7,   160] loss: 984.628, speed: 27.70, accuracy: 98.16 %\n",
      "[7,   170] loss: 1029.651, speed: 27.67, accuracy: 98.16 %\n",
      "[7,   180] loss: 1086.721, speed: 27.69, accuracy: 98.17 %\n",
      "[7,   190] loss: 1141.691, speed: 27.68, accuracy: 98.16 %\n",
      "[7,   200] loss: 1196.865, speed: 27.67, accuracy: 98.18 %\n",
      "[7,   210] loss: 1247.984, speed: 27.69, accuracy: 98.18 %\n",
      "[7,   220] loss: 1321.498, speed: 27.68, accuracy: 98.16 %\n",
      "[7,   230] loss: 1406.194, speed: 27.69, accuracy: 98.16 %\n",
      "[7,   240] loss: 1466.327, speed: 27.68, accuracy: 98.15 %\n",
      "[7,   250] loss: 1516.403, speed: 27.67, accuracy: 98.14 %\n",
      "[7,   260] loss: 1565.522, speed: 27.68, accuracy: 98.15 %\n",
      "[7,   270] loss: 1603.204, speed: 27.66, accuracy: 98.15 %\n",
      "[7,   280] loss: 1638.300, speed: 27.67, accuracy: 98.16 %\n",
      "[7,   290] loss: 1676.581, speed: 27.65, accuracy: 98.17 %\n",
      "[7,   300] loss: 1735.768, speed: 27.63, accuracy: 98.15 %\n",
      "[7,   310] loss: 1819.260, speed: 27.64, accuracy: 98.15 %\n",
      "[7,   320] loss: 1919.965, speed: 27.66, accuracy: 98.11 %\n",
      "[7,   330] loss: 1976.805, speed: 27.67, accuracy: 98.11 %\n",
      "[7,   340] loss: 2029.538, speed: 27.68, accuracy: 98.12 %\n",
      "[7,   350] loss: 2087.767, speed: 27.71, accuracy: 98.13 %\n",
      "[7,   360] loss: 2152.088, speed: 27.72, accuracy: 98.12 %\n",
      "[7,   370] loss: 2229.039, speed: 27.70, accuracy: 98.12 %\n",
      "[7,   380] loss: 2295.610, speed: 27.70, accuracy: 98.13 %\n",
      "[7,   390] loss: 2370.276, speed: 27.71, accuracy: 98.13 %\n",
      "[7,   400] loss: 2441.971, speed: 27.71, accuracy: 98.11 %\n",
      "[7,   410] loss: 2498.728, speed: 27.72, accuracy: 98.11 %\n",
      "[7,   420] loss: 2565.886, speed: 27.73, accuracy: 98.10 %\n",
      "[7,   430] loss: 2621.766, speed: 27.74, accuracy: 98.11 %\n",
      "[7,   440] loss: 2653.376, speed: 27.74, accuracy: 98.13 %\n",
      "[7,   450] loss: 2725.674, speed: 27.74, accuracy: 98.10 %\n",
      "[7,   460] loss: 2777.479, speed: 27.74, accuracy: 98.11 %\n",
      "[7,   470] loss: 2824.288, speed: 27.73, accuracy: 98.12 %\n",
      "[7,   480] loss: 2862.196, speed: 27.72, accuracy: 98.12 %\n",
      "[7,   490] loss: 2909.649, speed: 27.73, accuracy: 98.14 %\n",
      "[7,   500] loss: 2950.666, speed: 27.74, accuracy: 98.15 %\n",
      "[7,   510] loss: 2991.744, speed: 27.75, accuracy: 98.16 %\n",
      "[7,   520] loss: 3038.825, speed: 27.76, accuracy: 98.17 %\n",
      "[7,   530] loss: 3102.852, speed: 27.75, accuracy: 98.18 %\n",
      "[7,   540] loss: 3146.578, speed: 27.75, accuracy: 98.19 %\n",
      "[7,   550] loss: 3207.631, speed: 27.76, accuracy: 98.18 %\n",
      "[7,   560] loss: 3269.871, speed: 27.76, accuracy: 98.18 %\n",
      "[7,   570] loss: 3351.713, speed: 27.77, accuracy: 98.18 %\n",
      "[7,   580] loss: 3410.321, speed: 27.78, accuracy: 98.17 %\n",
      "[7,   590] loss: 3475.828, speed: 27.78, accuracy: 98.16 %\n",
      "[8,     0] loss: 6.630, speed: 26.32, accuracy: 98.00 %\n",
      "[8,    10] loss: 44.135, speed: 27.81, accuracy: 98.64 %\n",
      "[8,    20] loss: 90.612, speed: 27.76, accuracy: 98.52 %\n",
      "[8,    30] loss: 155.225, speed: 27.99, accuracy: 98.48 %\n",
      "[8,    40] loss: 206.415, speed: 27.84, accuracy: 98.46 %\n",
      "[8,    50] loss: 247.719, speed: 27.89, accuracy: 98.43 %\n",
      "[8,    60] loss: 284.968, speed: 27.71, accuracy: 98.52 %\n",
      "[8,    70] loss: 338.303, speed: 27.67, accuracy: 98.59 %\n",
      "[8,    80] loss: 403.429, speed: 27.70, accuracy: 98.56 %\n",
      "[8,    90] loss: 445.540, speed: 27.66, accuracy: 98.63 %\n",
      "[8,   100] loss: 483.845, speed: 27.63, accuracy: 98.63 %\n",
      "[8,   110] loss: 524.502, speed: 27.56, accuracy: 98.62 %\n",
      "[8,   120] loss: 575.728, speed: 27.57, accuracy: 98.60 %\n",
      "[8,   130] loss: 605.353, speed: 27.60, accuracy: 98.66 %\n",
      "[8,   140] loss: 641.172, speed: 27.57, accuracy: 98.67 %\n",
      "[8,   150] loss: 690.470, speed: 27.62, accuracy: 98.63 %\n",
      "[8,   160] loss: 750.636, speed: 27.65, accuracy: 98.59 %\n",
      "[8,   170] loss: 812.475, speed: 27.69, accuracy: 98.57 %\n",
      "[8,   180] loss: 858.459, speed: 27.69, accuracy: 98.56 %\n",
      "[8,   190] loss: 904.693, speed: 27.71, accuracy: 98.57 %\n",
      "[8,   200] loss: 952.815, speed: 27.69, accuracy: 98.56 %\n",
      "[8,   210] loss: 992.793, speed: 27.67, accuracy: 98.56 %\n",
      "[8,   220] loss: 1017.148, speed: 27.68, accuracy: 98.60 %\n",
      "[8,   230] loss: 1077.783, speed: 27.68, accuracy: 98.58 %\n",
      "[8,   240] loss: 1111.254, speed: 27.66, accuracy: 98.59 %\n",
      "[8,   250] loss: 1167.985, speed: 27.67, accuracy: 98.59 %\n",
      "[8,   260] loss: 1217.186, speed: 27.66, accuracy: 98.59 %\n",
      "[8,   270] loss: 1269.441, speed: 27.69, accuracy: 98.57 %\n",
      "[8,   280] loss: 1319.367, speed: 27.71, accuracy: 98.57 %\n",
      "[8,   290] loss: 1371.431, speed: 27.71, accuracy: 98.55 %\n",
      "[8,   300] loss: 1443.585, speed: 27.69, accuracy: 98.54 %\n",
      "[8,   310] loss: 1505.768, speed: 27.70, accuracy: 98.51 %\n",
      "[8,   320] loss: 1554.248, speed: 27.69, accuracy: 98.52 %\n",
      "[8,   330] loss: 1627.571, speed: 27.69, accuracy: 98.48 %\n",
      "[8,   340] loss: 1689.098, speed: 27.68, accuracy: 98.47 %\n",
      "[8,   350] loss: 1781.961, speed: 27.67, accuracy: 98.44 %\n",
      "[8,   360] loss: 1850.791, speed: 27.66, accuracy: 98.42 %\n",
      "[8,   370] loss: 1912.610, speed: 27.66, accuracy: 98.40 %\n",
      "[8,   380] loss: 2013.648, speed: 27.68, accuracy: 98.37 %\n",
      "[8,   390] loss: 2068.459, speed: 27.69, accuracy: 98.37 %\n",
      "[8,   400] loss: 2118.859, speed: 27.68, accuracy: 98.38 %\n",
      "[8,   410] loss: 2198.587, speed: 27.68, accuracy: 98.37 %\n",
      "[8,   420] loss: 2243.113, speed: 27.70, accuracy: 98.37 %\n",
      "[8,   430] loss: 2299.907, speed: 27.70, accuracy: 98.37 %\n",
      "[8,   440] loss: 2343.134, speed: 27.71, accuracy: 98.38 %\n",
      "[8,   450] loss: 2425.064, speed: 27.71, accuracy: 98.37 %\n",
      "[8,   460] loss: 2483.303, speed: 27.72, accuracy: 98.36 %\n",
      "[8,   470] loss: 2569.924, speed: 27.71, accuracy: 98.36 %\n",
      "[8,   480] loss: 2635.045, speed: 27.72, accuracy: 98.36 %\n",
      "[8,   490] loss: 2699.011, speed: 27.72, accuracy: 98.35 %\n",
      "[8,   500] loss: 2745.712, speed: 27.72, accuracy: 98.36 %\n",
      "[8,   510] loss: 2780.947, speed: 27.73, accuracy: 98.36 %\n",
      "[8,   520] loss: 2841.986, speed: 27.73, accuracy: 98.35 %\n",
      "[8,   530] loss: 2917.497, speed: 27.73, accuracy: 98.34 %\n",
      "[8,   540] loss: 2962.780, speed: 27.73, accuracy: 98.34 %\n",
      "[8,   550] loss: 3028.078, speed: 27.72, accuracy: 98.33 %\n",
      "[8,   560] loss: 3072.599, speed: 27.72, accuracy: 98.34 %\n",
      "[8,   570] loss: 3114.583, speed: 27.73, accuracy: 98.34 %\n",
      "[8,   580] loss: 3165.070, speed: 27.74, accuracy: 98.34 %\n",
      "[8,   590] loss: 3208.905, speed: 27.74, accuracy: 98.35 %\n",
      "[9,     0] loss: 5.134, speed: 27.78, accuracy: 98.00 %\n",
      "[9,    10] loss: 73.937, speed: 27.48, accuracy: 98.45 %\n",
      "[9,    20] loss: 104.538, speed: 27.16, accuracy: 98.71 %\n",
      "[9,    30] loss: 160.162, speed: 27.38, accuracy: 98.61 %\n",
      "[9,    40] loss: 199.445, speed: 27.55, accuracy: 98.66 %\n",
      "[9,    50] loss: 249.553, speed: 27.55, accuracy: 98.63 %\n",
      "[9,    60] loss: 284.847, speed: 27.62, accuracy: 98.62 %\n",
      "[9,    70] loss: 317.047, speed: 27.56, accuracy: 98.65 %\n",
      "[9,    80] loss: 362.787, speed: 27.61, accuracy: 98.63 %\n",
      "[9,    90] loss: 386.476, speed: 27.57, accuracy: 98.68 %\n",
      "[9,   100] loss: 429.067, speed: 27.63, accuracy: 98.64 %\n",
      "[9,   110] loss: 497.259, speed: 27.64, accuracy: 98.59 %\n",
      "[9,   120] loss: 553.059, speed: 27.66, accuracy: 98.54 %\n",
      "[9,   130] loss: 614.249, speed: 27.69, accuracy: 98.48 %\n",
      "[9,   140] loss: 689.775, speed: 27.69, accuracy: 98.39 %\n",
      "[9,   150] loss: 741.539, speed: 27.72, accuracy: 98.41 %\n",
      "[9,   160] loss: 786.832, speed: 27.75, accuracy: 98.43 %\n",
      "[9,   170] loss: 841.945, speed: 27.75, accuracy: 98.42 %\n",
      "[9,   180] loss: 899.582, speed: 27.71, accuracy: 98.43 %\n",
      "[9,   190] loss: 949.972, speed: 27.72, accuracy: 98.40 %\n",
      "[9,   200] loss: 1014.041, speed: 27.75, accuracy: 98.39 %\n",
      "[9,   210] loss: 1066.087, speed: 27.73, accuracy: 98.40 %\n",
      "[9,   220] loss: 1098.750, speed: 27.74, accuracy: 98.41 %\n",
      "[9,   230] loss: 1138.212, speed: 27.72, accuracy: 98.44 %\n",
      "[9,   240] loss: 1201.746, speed: 27.70, accuracy: 98.43 %\n",
      "[9,   250] loss: 1244.603, speed: 27.70, accuracy: 98.44 %\n",
      "[9,   260] loss: 1311.036, speed: 27.69, accuracy: 98.43 %\n",
      "[9,   270] loss: 1363.001, speed: 27.70, accuracy: 98.42 %\n",
      "[9,   280] loss: 1439.149, speed: 27.72, accuracy: 98.40 %\n",
      "[9,   290] loss: 1528.631, speed: 27.69, accuracy: 98.37 %\n",
      "[9,   300] loss: 1572.816, speed: 27.70, accuracy: 98.37 %\n",
      "[9,   310] loss: 1679.970, speed: 27.71, accuracy: 98.34 %\n",
      "[9,   320] loss: 1747.901, speed: 27.69, accuracy: 98.33 %\n",
      "[9,   330] loss: 1803.078, speed: 27.70, accuracy: 98.33 %\n",
      "[9,   340] loss: 1875.851, speed: 27.69, accuracy: 98.31 %\n",
      "[9,   350] loss: 1929.634, speed: 27.71, accuracy: 98.31 %\n",
      "[9,   360] loss: 1989.267, speed: 27.73, accuracy: 98.30 %\n",
      "[9,   370] loss: 2047.828, speed: 27.73, accuracy: 98.30 %\n",
      "[9,   380] loss: 2116.900, speed: 27.74, accuracy: 98.29 %\n",
      "[9,   390] loss: 2188.381, speed: 27.76, accuracy: 98.29 %\n",
      "[9,   400] loss: 2247.753, speed: 27.75, accuracy: 98.28 %\n",
      "[9,   410] loss: 2317.877, speed: 27.75, accuracy: 98.26 %\n",
      "[9,   420] loss: 2398.837, speed: 27.74, accuracy: 98.25 %\n",
      "[9,   430] loss: 2460.181, speed: 27.74, accuracy: 98.25 %\n",
      "[9,   440] loss: 2502.565, speed: 27.75, accuracy: 98.26 %\n",
      "[9,   450] loss: 2579.175, speed: 27.75, accuracy: 98.21 %\n",
      "[9,   460] loss: 2642.343, speed: 27.73, accuracy: 98.20 %\n",
      "[9,   470] loss: 2709.429, speed: 27.71, accuracy: 98.19 %\n",
      "[9,   480] loss: 2775.657, speed: 27.71, accuracy: 98.19 %\n",
      "[9,   490] loss: 2845.051, speed: 27.72, accuracy: 98.19 %\n",
      "[9,   500] loss: 2905.982, speed: 27.73, accuracy: 98.18 %\n",
      "[9,   510] loss: 2978.243, speed: 27.74, accuracy: 98.18 %\n",
      "[9,   520] loss: 3039.979, speed: 27.73, accuracy: 98.17 %\n",
      "[9,   530] loss: 3095.357, speed: 27.74, accuracy: 98.17 %\n",
      "[9,   540] loss: 3170.110, speed: 27.75, accuracy: 98.17 %\n",
      "[9,   550] loss: 3212.199, speed: 27.75, accuracy: 98.18 %\n",
      "[9,   560] loss: 3288.078, speed: 27.75, accuracy: 98.17 %\n",
      "[9,   570] loss: 3342.875, speed: 27.75, accuracy: 98.17 %\n",
      "[9,   580] loss: 3404.841, speed: 27.75, accuracy: 98.16 %\n",
      "[9,   590] loss: 3453.243, speed: 27.75, accuracy: 98.17 %\n",
      "[10,     0] loss: 2.675, speed: 26.32, accuracy: 99.00 %\n",
      "[10,    10] loss: 38.965, speed: 27.57, accuracy: 98.73 %\n",
      "[10,    20] loss: 103.946, speed: 28.00, accuracy: 98.62 %\n",
      "[10,    30] loss: 168.705, speed: 27.93, accuracy: 98.42 %\n",
      "[10,    40] loss: 230.238, speed: 27.68, accuracy: 98.32 %\n",
      "[10,    50] loss: 284.953, speed: 27.57, accuracy: 98.27 %\n",
      "[10,    60] loss: 323.074, speed: 27.61, accuracy: 98.34 %\n",
      "[10,    70] loss: 363.081, speed: 27.61, accuracy: 98.35 %\n",
      "[10,    80] loss: 396.529, speed: 27.65, accuracy: 98.41 %\n",
      "[10,    90] loss: 436.135, speed: 27.70, accuracy: 98.41 %\n",
      "[10,   100] loss: 474.915, speed: 27.68, accuracy: 98.43 %\n",
      "[10,   110] loss: 512.364, speed: 27.70, accuracy: 98.48 %\n",
      "[10,   120] loss: 547.077, speed: 27.71, accuracy: 98.51 %\n",
      "[10,   130] loss: 574.909, speed: 27.75, accuracy: 98.58 %\n",
      "[10,   140] loss: 598.841, speed: 27.75, accuracy: 98.61 %\n",
      "[10,   150] loss: 656.698, speed: 27.81, accuracy: 98.60 %\n",
      "[10,   160] loss: 705.378, speed: 27.77, accuracy: 98.63 %\n",
      "[10,   170] loss: 762.842, speed: 27.73, accuracy: 98.61 %\n",
      "[10,   180] loss: 832.245, speed: 27.72, accuracy: 98.56 %\n",
      "[10,   190] loss: 862.474, speed: 27.72, accuracy: 98.56 %\n",
      "[10,   200] loss: 900.775, speed: 27.74, accuracy: 98.55 %\n",
      "[10,   210] loss: 951.366, speed: 27.76, accuracy: 98.55 %\n",
      "[10,   220] loss: 1015.329, speed: 27.75, accuracy: 98.51 %\n",
      "[10,   230] loss: 1079.151, speed: 27.74, accuracy: 98.49 %\n",
      "[10,   240] loss: 1132.566, speed: 27.75, accuracy: 98.47 %\n",
      "[10,   250] loss: 1189.472, speed: 27.76, accuracy: 98.46 %\n",
      "[10,   260] loss: 1242.123, speed: 27.77, accuracy: 98.48 %\n",
      "[10,   270] loss: 1303.899, speed: 27.78, accuracy: 98.46 %\n",
      "[10,   280] loss: 1351.845, speed: 27.76, accuracy: 98.47 %\n",
      "[10,   290] loss: 1393.309, speed: 27.75, accuracy: 98.48 %\n",
      "[10,   300] loss: 1487.484, speed: 27.75, accuracy: 98.45 %\n",
      "[10,   310] loss: 1553.188, speed: 27.73, accuracy: 98.44 %\n",
      "[10,   320] loss: 1580.895, speed: 27.72, accuracy: 98.45 %\n",
      "[10,   330] loss: 1632.617, speed: 27.72, accuracy: 98.44 %\n",
      "[10,   340] loss: 1704.097, speed: 27.70, accuracy: 98.44 %\n",
      "[10,   350] loss: 1756.430, speed: 27.71, accuracy: 98.44 %\n",
      "[10,   360] loss: 1814.701, speed: 27.73, accuracy: 98.42 %\n",
      "[10,   370] loss: 1884.682, speed: 27.72, accuracy: 98.41 %\n",
      "[10,   380] loss: 1925.838, speed: 27.73, accuracy: 98.42 %\n",
      "[10,   390] loss: 1962.524, speed: 27.71, accuracy: 98.43 %\n",
      "[10,   400] loss: 2002.386, speed: 27.72, accuracy: 98.44 %\n",
      "[10,   410] loss: 2072.437, speed: 27.70, accuracy: 98.43 %\n",
      "[10,   420] loss: 2097.390, speed: 27.70, accuracy: 98.44 %\n",
      "[10,   430] loss: 2164.407, speed: 27.70, accuracy: 98.44 %\n",
      "[10,   440] loss: 2213.603, speed: 27.70, accuracy: 98.43 %\n",
      "[10,   450] loss: 2259.828, speed: 27.68, accuracy: 98.43 %\n",
      "[10,   460] loss: 2332.266, speed: 27.69, accuracy: 98.41 %\n",
      "[10,   470] loss: 2383.279, speed: 27.69, accuracy: 98.40 %\n",
      "[10,   480] loss: 2409.474, speed: 27.68, accuracy: 98.41 %\n",
      "[10,   490] loss: 2493.934, speed: 27.68, accuracy: 98.42 %\n",
      "[10,   500] loss: 2589.655, speed: 27.69, accuracy: 98.40 %\n",
      "[10,   510] loss: 2642.592, speed: 27.66, accuracy: 98.41 %\n",
      "[10,   520] loss: 2691.213, speed: 27.66, accuracy: 98.41 %\n",
      "[10,   530] loss: 2757.254, speed: 27.67, accuracy: 98.41 %\n",
      "[10,   540] loss: 2796.332, speed: 27.66, accuracy: 98.41 %\n",
      "[10,   550] loss: 2863.741, speed: 27.67, accuracy: 98.40 %\n",
      "[10,   560] loss: 2909.946, speed: 27.67, accuracy: 98.40 %\n",
      "[10,   570] loss: 2981.130, speed: 27.67, accuracy: 98.39 %\n",
      "[10,   580] loss: 3055.624, speed: 27.67, accuracy: 98.38 %\n",
      "[10,   590] loss: 3125.111, speed: 27.67, accuracy: 98.37 %\n",
      "[11,     0] loss: 3.317, speed: 27.78, accuracy: 99.00 %\n",
      "[11,    10] loss: 55.779, speed: 27.92, accuracy: 98.09 %\n",
      "[11,    20] loss: 122.720, speed: 27.70, accuracy: 98.10 %\n",
      "[11,    30] loss: 184.193, speed: 27.85, accuracy: 98.23 %\n",
      "[11,    40] loss: 258.818, speed: 27.80, accuracy: 98.12 %\n",
      "[11,    50] loss: 304.330, speed: 27.82, accuracy: 98.20 %\n",
      "[11,    60] loss: 376.527, speed: 27.92, accuracy: 98.23 %\n",
      "[11,    70] loss: 449.022, speed: 27.93, accuracy: 98.17 %\n",
      "[11,    80] loss: 496.019, speed: 27.91, accuracy: 98.21 %\n",
      "[11,    90] loss: 547.272, speed: 27.85, accuracy: 98.18 %\n",
      "[11,   100] loss: 611.354, speed: 27.86, accuracy: 98.20 %\n",
      "[11,   110] loss: 644.607, speed: 27.83, accuracy: 98.26 %\n",
      "[11,   120] loss: 716.440, speed: 27.79, accuracy: 98.29 %\n",
      "[11,   130] loss: 765.845, speed: 27.81, accuracy: 98.31 %\n",
      "[11,   140] loss: 817.700, speed: 27.87, accuracy: 98.31 %\n",
      "[11,   150] loss: 872.083, speed: 27.82, accuracy: 98.31 %\n",
      "[11,   160] loss: 929.300, speed: 27.77, accuracy: 98.29 %\n",
      "[11,   170] loss: 989.558, speed: 27.77, accuracy: 98.27 %\n",
      "[11,   180] loss: 1042.395, speed: 27.76, accuracy: 98.28 %\n",
      "[11,   190] loss: 1096.190, speed: 27.74, accuracy: 98.26 %\n",
      "[11,   200] loss: 1129.096, speed: 27.73, accuracy: 98.29 %\n",
      "[11,   210] loss: 1224.023, speed: 27.72, accuracy: 98.26 %\n",
      "[11,   220] loss: 1276.091, speed: 27.74, accuracy: 98.25 %\n",
      "[11,   230] loss: 1309.076, speed: 27.76, accuracy: 98.27 %\n",
      "[11,   240] loss: 1366.177, speed: 27.76, accuracy: 98.27 %\n",
      "[11,   250] loss: 1421.174, speed: 27.77, accuracy: 98.29 %\n",
      "[11,   260] loss: 1467.725, speed: 27.79, accuracy: 98.29 %\n",
      "[11,   270] loss: 1504.104, speed: 27.80, accuracy: 98.30 %\n",
      "[11,   280] loss: 1548.088, speed: 27.78, accuracy: 98.30 %\n",
      "[11,   290] loss: 1577.672, speed: 27.75, accuracy: 98.33 %\n",
      "[11,   300] loss: 1605.825, speed: 27.76, accuracy: 98.35 %\n",
      "[11,   310] loss: 1650.200, speed: 27.76, accuracy: 98.37 %\n",
      "[11,   320] loss: 1711.695, speed: 27.76, accuracy: 98.36 %\n",
      "[11,   330] loss: 1765.725, speed: 27.76, accuracy: 98.37 %\n",
      "[11,   340] loss: 1818.309, speed: 27.76, accuracy: 98.37 %\n",
      "[11,   350] loss: 1844.324, speed: 27.76, accuracy: 98.40 %\n",
      "[11,   360] loss: 1906.719, speed: 27.73, accuracy: 98.39 %\n",
      "[11,   370] loss: 1962.187, speed: 27.75, accuracy: 98.39 %\n",
      "[11,   380] loss: 1995.439, speed: 27.73, accuracy: 98.40 %\n",
      "[11,   390] loss: 2045.224, speed: 27.74, accuracy: 98.40 %\n",
      "[11,   400] loss: 2101.252, speed: 27.74, accuracy: 98.41 %\n",
      "[11,   410] loss: 2157.986, speed: 27.74, accuracy: 98.39 %\n",
      "[11,   420] loss: 2184.452, speed: 27.73, accuracy: 98.41 %\n",
      "[11,   430] loss: 2208.915, speed: 27.75, accuracy: 98.42 %\n",
      "[11,   440] loss: 2259.030, speed: 27.75, accuracy: 98.43 %\n",
      "[11,   450] loss: 2327.858, speed: 27.74, accuracy: 98.41 %\n",
      "[11,   460] loss: 2396.128, speed: 27.74, accuracy: 98.41 %\n",
      "[11,   470] loss: 2445.930, speed: 27.75, accuracy: 98.41 %\n",
      "[11,   480] loss: 2495.383, speed: 27.75, accuracy: 98.41 %\n",
      "[11,   490] loss: 2536.224, speed: 27.75, accuracy: 98.41 %\n",
      "[11,   500] loss: 2591.414, speed: 27.74, accuracy: 98.41 %\n",
      "[11,   510] loss: 2646.120, speed: 27.75, accuracy: 98.40 %\n",
      "[11,   520] loss: 2702.868, speed: 27.76, accuracy: 98.41 %\n",
      "[11,   530] loss: 2768.813, speed: 27.75, accuracy: 98.40 %\n",
      "[11,   540] loss: 2807.460, speed: 27.73, accuracy: 98.41 %\n",
      "[11,   550] loss: 2886.942, speed: 27.72, accuracy: 98.40 %\n",
      "[11,   560] loss: 2954.430, speed: 27.72, accuracy: 98.40 %\n",
      "[11,   570] loss: 3014.082, speed: 27.71, accuracy: 98.40 %\n",
      "[11,   580] loss: 3088.657, speed: 27.71, accuracy: 98.39 %\n",
      "[11,   590] loss: 3130.012, speed: 27.71, accuracy: 98.39 %\n",
      "[12,     0] loss: 23.394, speed: 25.64, accuracy: 97.00 %\n",
      "[12,    10] loss: 73.150, speed: 27.30, accuracy: 98.18 %\n",
      "[12,    20] loss: 115.600, speed: 27.10, accuracy: 98.24 %\n",
      "[12,    30] loss: 157.326, speed: 27.00, accuracy: 98.45 %\n",
      "[12,    40] loss: 191.463, speed: 26.89, accuracy: 98.46 %\n",
      "[12,    50] loss: 239.520, speed: 26.93, accuracy: 98.55 %\n",
      "[12,    60] loss: 283.816, speed: 27.14, accuracy: 98.59 %\n",
      "[12,    70] loss: 319.200, speed: 27.04, accuracy: 98.61 %\n",
      "[12,    80] loss: 357.278, speed: 27.18, accuracy: 98.59 %\n",
      "[12,    90] loss: 399.729, speed: 27.24, accuracy: 98.60 %\n",
      "[12,   100] loss: 445.146, speed: 27.30, accuracy: 98.61 %\n",
      "[12,   110] loss: 479.979, speed: 27.34, accuracy: 98.68 %\n",
      "[12,   120] loss: 527.059, speed: 27.40, accuracy: 98.69 %\n",
      "[12,   130] loss: 601.461, speed: 27.38, accuracy: 98.65 %\n",
      "[12,   140] loss: 647.666, speed: 27.42, accuracy: 98.63 %\n",
      "[12,   150] loss: 720.381, speed: 27.47, accuracy: 98.57 %\n",
      "[12,   160] loss: 767.746, speed: 27.50, accuracy: 98.58 %\n",
      "[12,   170] loss: 820.360, speed: 27.55, accuracy: 98.57 %\n",
      "[12,   180] loss: 871.550, speed: 27.58, accuracy: 98.57 %\n",
      "[12,   190] loss: 923.811, speed: 27.58, accuracy: 98.56 %\n",
      "[12,   200] loss: 963.077, speed: 27.60, accuracy: 98.58 %\n",
      "[12,   210] loss: 1005.449, speed: 27.60, accuracy: 98.59 %\n",
      "[12,   220] loss: 1024.868, speed: 27.61, accuracy: 98.63 %\n",
      "[12,   230] loss: 1063.380, speed: 27.67, accuracy: 98.64 %\n",
      "[12,   240] loss: 1142.908, speed: 27.70, accuracy: 98.60 %\n",
      "[12,   250] loss: 1252.005, speed: 27.69, accuracy: 98.55 %\n",
      "[12,   260] loss: 1307.277, speed: 27.71, accuracy: 98.55 %\n",
      "[12,   270] loss: 1374.634, speed: 27.73, accuracy: 98.52 %\n",
      "[12,   280] loss: 1428.712, speed: 27.74, accuracy: 98.51 %\n",
      "[12,   290] loss: 1499.618, speed: 27.74, accuracy: 98.48 %\n",
      "[12,   300] loss: 1573.204, speed: 27.75, accuracy: 98.45 %\n",
      "[12,   310] loss: 1633.672, speed: 27.67, accuracy: 98.44 %\n",
      "[12,   320] loss: 1682.308, speed: 27.64, accuracy: 98.44 %\n",
      "[12,   330] loss: 1747.708, speed: 27.65, accuracy: 98.43 %\n",
      "[12,   340] loss: 1802.846, speed: 27.66, accuracy: 98.43 %\n",
      "[12,   350] loss: 1843.297, speed: 27.67, accuracy: 98.43 %\n",
      "[12,   360] loss: 1898.144, speed: 27.67, accuracy: 98.42 %\n",
      "[12,   370] loss: 1953.356, speed: 27.68, accuracy: 98.42 %\n",
      "[12,   380] loss: 2000.489, speed: 27.66, accuracy: 98.42 %\n",
      "[12,   390] loss: 2046.239, speed: 27.65, accuracy: 98.43 %\n",
      "[12,   400] loss: 2094.816, speed: 27.64, accuracy: 98.44 %\n",
      "[12,   410] loss: 2167.957, speed: 27.59, accuracy: 98.42 %\n",
      "[12,   420] loss: 2212.066, speed: 27.54, accuracy: 98.41 %\n",
      "[12,   430] loss: 2255.023, speed: 27.52, accuracy: 98.41 %\n",
      "[12,   440] loss: 2311.332, speed: 27.53, accuracy: 98.42 %\n",
      "[12,   450] loss: 2384.609, speed: 27.55, accuracy: 98.41 %\n",
      "[12,   460] loss: 2442.752, speed: 27.55, accuracy: 98.40 %\n",
      "[12,   470] loss: 2494.604, speed: 27.55, accuracy: 98.40 %\n",
      "[12,   480] loss: 2541.798, speed: 27.55, accuracy: 98.41 %\n",
      "[12,   490] loss: 2572.962, speed: 27.55, accuracy: 98.41 %\n",
      "[12,   500] loss: 2646.825, speed: 27.55, accuracy: 98.41 %\n",
      "[12,   510] loss: 2721.521, speed: 27.53, accuracy: 98.40 %\n",
      "[12,   520] loss: 2769.369, speed: 27.53, accuracy: 98.40 %\n",
      "[12,   530] loss: 2823.646, speed: 27.55, accuracy: 98.39 %\n",
      "[12,   540] loss: 2862.174, speed: 27.53, accuracy: 98.40 %\n",
      "[12,   550] loss: 2900.888, speed: 27.54, accuracy: 98.41 %\n",
      "[12,   560] loss: 2940.681, speed: 27.55, accuracy: 98.42 %\n",
      "[12,   570] loss: 2994.434, speed: 27.55, accuracy: 98.43 %\n",
      "[12,   580] loss: 3056.950, speed: 27.55, accuracy: 98.42 %\n",
      "[12,   590] loss: 3140.445, speed: 27.55, accuracy: 98.41 %\n",
      "[13,     0] loss: 11.102, speed: 25.00, accuracy: 98.00 %\n",
      "[13,    10] loss: 45.588, speed: 27.71, accuracy: 98.45 %\n",
      "[13,    20] loss: 79.945, speed: 27.81, accuracy: 98.48 %\n",
      "[13,    30] loss: 117.780, speed: 27.85, accuracy: 98.65 %\n",
      "[13,    40] loss: 184.835, speed: 27.95, accuracy: 98.59 %\n",
      "[13,    50] loss: 243.817, speed: 27.90, accuracy: 98.49 %\n",
      "[13,    60] loss: 297.860, speed: 27.84, accuracy: 98.43 %\n",
      "[13,    70] loss: 345.096, speed: 27.86, accuracy: 98.41 %\n",
      "[13,    80] loss: 379.177, speed: 27.84, accuracy: 98.48 %\n",
      "[13,    90] loss: 412.575, speed: 27.80, accuracy: 98.54 %\n",
      "[13,   100] loss: 452.809, speed: 27.79, accuracy: 98.55 %\n",
      "[13,   110] loss: 510.989, speed: 27.74, accuracy: 98.53 %\n",
      "[13,   120] loss: 567.096, speed: 27.75, accuracy: 98.50 %\n",
      "[13,   130] loss: 646.640, speed: 27.76, accuracy: 98.47 %\n",
      "[13,   140] loss: 704.265, speed: 27.77, accuracy: 98.47 %\n",
      "[13,   150] loss: 785.702, speed: 27.77, accuracy: 98.45 %\n",
      "[13,   160] loss: 831.790, speed: 27.79, accuracy: 98.46 %\n",
      "[13,   170] loss: 882.748, speed: 27.80, accuracy: 98.44 %\n",
      "[13,   180] loss: 915.219, speed: 27.79, accuracy: 98.48 %\n",
      "[13,   190] loss: 957.465, speed: 27.78, accuracy: 98.48 %\n",
      "[13,   200] loss: 1000.596, speed: 27.79, accuracy: 98.49 %\n",
      "[13,   210] loss: 1030.970, speed: 27.77, accuracy: 98.50 %\n",
      "[13,   220] loss: 1064.148, speed: 27.77, accuracy: 98.52 %\n",
      "[13,   230] loss: 1098.186, speed: 27.78, accuracy: 98.53 %\n",
      "[13,   240] loss: 1144.388, speed: 27.77, accuracy: 98.54 %\n",
      "[13,   250] loss: 1192.321, speed: 27.77, accuracy: 98.54 %\n",
      "[13,   260] loss: 1274.948, speed: 27.77, accuracy: 98.50 %\n",
      "[13,   270] loss: 1310.521, speed: 27.76, accuracy: 98.51 %\n",
      "[13,   280] loss: 1360.651, speed: 27.74, accuracy: 98.49 %\n",
      "[13,   290] loss: 1416.300, speed: 27.72, accuracy: 98.49 %\n",
      "[13,   300] loss: 1468.121, speed: 27.73, accuracy: 98.50 %\n",
      "[13,   310] loss: 1515.499, speed: 27.72, accuracy: 98.49 %\n",
      "[13,   320] loss: 1593.159, speed: 27.71, accuracy: 98.46 %\n",
      "[13,   330] loss: 1683.710, speed: 27.69, accuracy: 98.43 %\n",
      "[13,   340] loss: 1757.718, speed: 27.69, accuracy: 98.42 %\n",
      "[13,   350] loss: 1814.999, speed: 27.68, accuracy: 98.41 %\n",
      "[13,   360] loss: 1903.456, speed: 27.67, accuracy: 98.40 %\n",
      "[13,   370] loss: 1961.961, speed: 27.68, accuracy: 98.39 %\n",
      "[13,   380] loss: 1991.900, speed: 27.70, accuracy: 98.41 %\n",
      "[13,   390] loss: 2055.722, speed: 27.71, accuracy: 98.40 %\n",
      "[13,   400] loss: 2101.115, speed: 27.70, accuracy: 98.39 %\n",
      "[13,   410] loss: 2176.922, speed: 27.69, accuracy: 98.39 %\n",
      "[13,   420] loss: 2238.023, speed: 27.69, accuracy: 98.38 %\n",
      "[13,   430] loss: 2296.609, speed: 27.67, accuracy: 98.38 %\n",
      "[13,   440] loss: 2333.283, speed: 27.68, accuracy: 98.39 %\n",
      "[13,   450] loss: 2408.613, speed: 27.67, accuracy: 98.39 %\n",
      "[13,   460] loss: 2453.463, speed: 27.67, accuracy: 98.39 %\n",
      "[13,   470] loss: 2498.024, speed: 27.67, accuracy: 98.40 %\n",
      "[13,   480] loss: 2548.128, speed: 27.68, accuracy: 98.41 %\n",
      "[13,   490] loss: 2592.731, speed: 27.67, accuracy: 98.41 %\n",
      "[13,   500] loss: 2675.212, speed: 27.66, accuracy: 98.40 %\n",
      "[13,   510] loss: 2744.749, speed: 27.66, accuracy: 98.38 %\n",
      "[13,   520] loss: 2794.456, speed: 27.67, accuracy: 98.37 %\n",
      "[13,   530] loss: 2832.923, speed: 27.65, accuracy: 98.38 %\n",
      "[13,   540] loss: 2915.343, speed: 27.66, accuracy: 98.37 %\n",
      "[13,   550] loss: 3005.154, speed: 27.66, accuracy: 98.35 %\n",
      "[13,   560] loss: 3078.205, speed: 27.66, accuracy: 98.34 %\n",
      "[13,   570] loss: 3120.639, speed: 27.66, accuracy: 98.35 %\n",
      "[13,   580] loss: 3168.909, speed: 27.67, accuracy: 98.35 %\n",
      "[13,   590] loss: 3220.246, speed: 27.66, accuracy: 98.35 %\n",
      "[14,     0] loss: 0.097, speed: 27.78, accuracy: 100.00 %\n",
      "[14,    10] loss: 30.573, speed: 28.06, accuracy: 98.91 %\n",
      "[14,    20] loss: 74.388, speed: 28.26, accuracy: 98.52 %\n",
      "[14,    30] loss: 108.324, speed: 28.00, accuracy: 98.68 %\n",
      "[14,    40] loss: 192.562, speed: 27.97, accuracy: 98.39 %\n",
      "[14,    50] loss: 242.203, speed: 27.69, accuracy: 98.35 %\n",
      "[14,    60] loss: 286.083, speed: 27.70, accuracy: 98.36 %\n",
      "[14,    70] loss: 309.816, speed: 27.69, accuracy: 98.51 %\n",
      "[14,    80] loss: 332.545, speed: 27.67, accuracy: 98.57 %\n",
      "[14,    90] loss: 382.665, speed: 27.65, accuracy: 98.55 %\n",
      "[14,   100] loss: 437.029, speed: 27.58, accuracy: 98.50 %\n",
      "[14,   110] loss: 473.688, speed: 27.46, accuracy: 98.51 %\n",
      "[14,   120] loss: 541.903, speed: 27.49, accuracy: 98.51 %\n",
      "[14,   130] loss: 602.416, speed: 27.45, accuracy: 98.50 %\n",
      "[14,   140] loss: 647.228, speed: 27.38, accuracy: 98.48 %\n",
      "[14,   150] loss: 687.256, speed: 27.40, accuracy: 98.50 %\n",
      "[14,   160] loss: 712.027, speed: 27.42, accuracy: 98.53 %\n",
      "[14,   170] loss: 742.020, speed: 27.43, accuracy: 98.57 %\n",
      "[14,   180] loss: 805.790, speed: 27.44, accuracy: 98.56 %\n",
      "[14,   190] loss: 860.789, speed: 27.46, accuracy: 98.53 %\n",
      "[14,   200] loss: 907.799, speed: 27.47, accuracy: 98.54 %\n",
      "[14,   210] loss: 957.327, speed: 27.47, accuracy: 98.54 %\n",
      "[14,   220] loss: 1001.705, speed: 27.47, accuracy: 98.52 %\n",
      "[14,   230] loss: 1029.457, speed: 27.50, accuracy: 98.54 %\n",
      "[14,   240] loss: 1084.892, speed: 27.49, accuracy: 98.55 %\n",
      "[14,   250] loss: 1159.518, speed: 27.50, accuracy: 98.53 %\n",
      "[14,   260] loss: 1209.803, speed: 27.51, accuracy: 98.52 %\n",
      "[14,   270] loss: 1245.861, speed: 27.52, accuracy: 98.54 %\n",
      "[14,   280] loss: 1282.147, speed: 27.50, accuracy: 98.54 %\n",
      "[14,   290] loss: 1350.766, speed: 27.51, accuracy: 98.53 %\n",
      "[14,   300] loss: 1393.935, speed: 27.52, accuracy: 98.54 %\n",
      "[14,   310] loss: 1443.698, speed: 27.52, accuracy: 98.54 %\n",
      "[14,   320] loss: 1487.912, speed: 27.53, accuracy: 98.54 %\n",
      "[14,   330] loss: 1531.422, speed: 27.53, accuracy: 98.54 %\n",
      "[14,   340] loss: 1559.602, speed: 27.54, accuracy: 98.55 %\n",
      "[14,   350] loss: 1613.102, speed: 27.54, accuracy: 98.54 %\n",
      "[14,   360] loss: 1672.417, speed: 27.54, accuracy: 98.55 %\n",
      "[14,   370] loss: 1707.972, speed: 27.55, accuracy: 98.56 %\n",
      "[14,   380] loss: 1757.784, speed: 27.54, accuracy: 98.55 %\n",
      "[14,   390] loss: 1811.830, speed: 27.52, accuracy: 98.54 %\n",
      "[14,   400] loss: 1850.524, speed: 27.52, accuracy: 98.55 %\n",
      "[14,   410] loss: 1914.471, speed: 27.52, accuracy: 98.54 %\n",
      "[14,   420] loss: 1979.012, speed: 27.52, accuracy: 98.53 %\n",
      "[14,   430] loss: 2032.337, speed: 27.50, accuracy: 98.52 %\n",
      "[14,   440] loss: 2089.845, speed: 27.50, accuracy: 98.52 %\n",
      "[14,   450] loss: 2149.823, speed: 27.49, accuracy: 98.51 %\n",
      "[14,   460] loss: 2201.117, speed: 27.50, accuracy: 98.51 %\n",
      "[14,   470] loss: 2251.328, speed: 27.50, accuracy: 98.51 %\n",
      "[14,   480] loss: 2302.250, speed: 27.51, accuracy: 98.51 %\n",
      "[14,   490] loss: 2367.402, speed: 27.51, accuracy: 98.50 %\n",
      "[14,   500] loss: 2418.286, speed: 27.52, accuracy: 98.50 %\n",
      "[14,   510] loss: 2473.693, speed: 27.51, accuracy: 98.50 %\n",
      "[14,   520] loss: 2503.413, speed: 27.50, accuracy: 98.51 %\n",
      "[14,   530] loss: 2559.346, speed: 27.50, accuracy: 98.50 %\n",
      "[14,   540] loss: 2606.544, speed: 27.50, accuracy: 98.51 %\n",
      "[14,   550] loss: 2662.163, speed: 27.51, accuracy: 98.51 %\n",
      "[14,   560] loss: 2710.352, speed: 27.52, accuracy: 98.51 %\n",
      "[14,   570] loss: 2768.993, speed: 27.52, accuracy: 98.51 %\n",
      "[14,   580] loss: 2842.338, speed: 27.53, accuracy: 98.48 %\n",
      "[14,   590] loss: 2917.993, speed: 27.51, accuracy: 98.47 %\n",
      "[15,     0] loss: 3.961, speed: 26.32, accuracy: 99.00 %\n",
      "[15,    10] loss: 79.071, speed: 26.90, accuracy: 97.64 %\n",
      "[15,    20] loss: 148.608, speed: 27.20, accuracy: 97.90 %\n",
      "[15,    30] loss: 193.807, speed: 27.22, accuracy: 98.10 %\n",
      "[15,    40] loss: 232.980, speed: 27.33, accuracy: 98.29 %\n",
      "[15,    50] loss: 270.423, speed: 27.43, accuracy: 98.39 %\n",
      "[15,    60] loss: 290.577, speed: 27.34, accuracy: 98.56 %\n",
      "[15,    70] loss: 332.713, speed: 27.42, accuracy: 98.56 %\n",
      "[15,    80] loss: 373.960, speed: 27.53, accuracy: 98.58 %\n",
      "[15,    90] loss: 423.104, speed: 27.49, accuracy: 98.59 %\n",
      "[15,   100] loss: 488.653, speed: 27.51, accuracy: 98.56 %\n",
      "[15,   110] loss: 535.341, speed: 27.51, accuracy: 98.53 %\n",
      "[15,   120] loss: 583.428, speed: 27.54, accuracy: 98.50 %\n",
      "[15,   130] loss: 603.456, speed: 27.53, accuracy: 98.56 %\n",
      "[15,   140] loss: 649.967, speed: 27.57, accuracy: 98.54 %\n",
      "[15,   150] loss: 703.399, speed: 27.55, accuracy: 98.52 %\n",
      "[15,   160] loss: 740.781, speed: 27.57, accuracy: 98.53 %\n",
      "[15,   170] loss: 784.304, speed: 27.59, accuracy: 98.56 %\n",
      "[15,   180] loss: 822.838, speed: 27.55, accuracy: 98.58 %\n",
      "[15,   190] loss: 871.102, speed: 27.57, accuracy: 98.58 %\n",
      "[15,   200] loss: 909.756, speed: 27.57, accuracy: 98.58 %\n",
      "[15,   210] loss: 999.003, speed: 27.56, accuracy: 98.53 %\n",
      "[15,   220] loss: 1079.882, speed: 27.58, accuracy: 98.52 %\n",
      "[15,   230] loss: 1139.786, speed: 27.59, accuracy: 98.52 %\n",
      "[15,   240] loss: 1186.828, speed: 27.58, accuracy: 98.51 %\n",
      "[15,   250] loss: 1236.597, speed: 27.60, accuracy: 98.52 %\n",
      "[15,   260] loss: 1282.024, speed: 27.60, accuracy: 98.52 %\n",
      "[15,   270] loss: 1343.072, speed: 27.58, accuracy: 98.53 %\n",
      "[15,   280] loss: 1396.664, speed: 27.60, accuracy: 98.53 %\n",
      "[15,   290] loss: 1462.809, speed: 27.59, accuracy: 98.51 %\n",
      "[15,   300] loss: 1551.060, speed: 27.60, accuracy: 98.48 %\n",
      "[15,   310] loss: 1615.921, speed: 27.58, accuracy: 98.46 %\n",
      "[15,   320] loss: 1690.104, speed: 27.56, accuracy: 98.44 %\n",
      "[15,   330] loss: 1739.471, speed: 27.55, accuracy: 98.42 %\n",
      "[15,   340] loss: 1771.802, speed: 27.55, accuracy: 98.44 %\n",
      "[15,   350] loss: 1850.239, speed: 27.56, accuracy: 98.42 %\n",
      "[15,   360] loss: 1911.553, speed: 27.56, accuracy: 98.41 %\n",
      "[15,   370] loss: 1972.659, speed: 27.55, accuracy: 98.40 %\n",
      "[15,   380] loss: 2016.029, speed: 27.53, accuracy: 98.41 %\n",
      "[15,   390] loss: 2066.726, speed: 27.54, accuracy: 98.42 %\n",
      "[15,   400] loss: 2094.448, speed: 27.52, accuracy: 98.44 %\n",
      "[15,   410] loss: 2138.966, speed: 27.52, accuracy: 98.44 %\n",
      "[15,   420] loss: 2175.404, speed: 27.52, accuracy: 98.44 %\n",
      "[15,   430] loss: 2226.800, speed: 27.51, accuracy: 98.45 %\n",
      "[15,   440] loss: 2295.799, speed: 27.51, accuracy: 98.45 %\n",
      "[15,   450] loss: 2355.024, speed: 27.51, accuracy: 98.45 %\n",
      "[15,   460] loss: 2421.202, speed: 27.50, accuracy: 98.44 %\n",
      "[15,   470] loss: 2475.652, speed: 27.50, accuracy: 98.43 %\n",
      "[15,   480] loss: 2539.926, speed: 27.49, accuracy: 98.42 %\n",
      "[15,   490] loss: 2611.106, speed: 27.48, accuracy: 98.41 %\n",
      "[15,   500] loss: 2657.440, speed: 27.46, accuracy: 98.41 %\n",
      "[15,   510] loss: 2706.483, speed: 27.46, accuracy: 98.42 %\n",
      "[15,   520] loss: 2764.693, speed: 27.46, accuracy: 98.41 %\n",
      "[15,   530] loss: 2809.070, speed: 27.46, accuracy: 98.42 %\n",
      "[15,   540] loss: 2846.827, speed: 27.46, accuracy: 98.42 %\n",
      "[15,   550] loss: 2910.228, speed: 27.45, accuracy: 98.42 %\n",
      "[15,   560] loss: 2953.020, speed: 27.45, accuracy: 98.42 %\n",
      "[15,   570] loss: 3008.622, speed: 27.45, accuracy: 98.42 %\n",
      "[15,   580] loss: 3052.481, speed: 27.46, accuracy: 98.43 %\n",
      "[15,   590] loss: 3120.825, speed: 27.45, accuracy: 98.42 %\n",
      "[16,     0] loss: 2.289, speed: 27.78, accuracy: 99.00 %\n",
      "[16,    10] loss: 35.584, speed: 27.43, accuracy: 98.82 %\n",
      "[16,    20] loss: 65.721, speed: 26.89, accuracy: 98.86 %\n",
      "[16,    30] loss: 99.496, speed: 27.03, accuracy: 98.97 %\n",
      "[16,    40] loss: 116.779, speed: 27.13, accuracy: 99.05 %\n",
      "[16,    50] loss: 137.074, speed: 27.24, accuracy: 99.06 %\n",
      "[16,    60] loss: 170.018, speed: 27.28, accuracy: 99.08 %\n",
      "[16,    70] loss: 205.612, speed: 27.28, accuracy: 99.07 %\n",
      "[16,    80] loss: 243.385, speed: 27.22, accuracy: 99.01 %\n",
      "[16,    90] loss: 267.466, speed: 27.26, accuracy: 99.02 %\n",
      "[16,   100] loss: 308.444, speed: 27.28, accuracy: 98.96 %\n",
      "[16,   110] loss: 333.110, speed: 27.33, accuracy: 99.01 %\n",
      "[16,   120] loss: 376.245, speed: 27.37, accuracy: 98.98 %\n",
      "[16,   130] loss: 460.293, speed: 27.39, accuracy: 98.91 %\n",
      "[16,   140] loss: 575.035, speed: 27.35, accuracy: 98.85 %\n",
      "[16,   150] loss: 666.279, speed: 27.38, accuracy: 98.78 %\n",
      "[16,   160] loss: 717.409, speed: 27.40, accuracy: 98.74 %\n",
      "[16,   170] loss: 755.664, speed: 27.43, accuracy: 98.75 %\n",
      "[16,   180] loss: 785.773, speed: 27.42, accuracy: 98.76 %\n",
      "[16,   190] loss: 836.211, speed: 27.42, accuracy: 98.75 %\n",
      "[16,   200] loss: 871.977, speed: 27.41, accuracy: 98.74 %\n",
      "[16,   210] loss: 906.626, speed: 27.42, accuracy: 98.74 %\n",
      "[16,   220] loss: 937.948, speed: 27.39, accuracy: 98.75 %\n",
      "[16,   230] loss: 997.649, speed: 27.40, accuracy: 98.73 %\n",
      "[16,   240] loss: 1047.409, speed: 27.39, accuracy: 98.73 %\n",
      "[16,   250] loss: 1088.504, speed: 27.36, accuracy: 98.74 %\n",
      "[16,   260] loss: 1129.990, speed: 27.39, accuracy: 98.73 %\n",
      "[16,   270] loss: 1182.369, speed: 27.39, accuracy: 98.72 %\n",
      "[16,   280] loss: 1221.259, speed: 27.42, accuracy: 98.73 %\n",
      "[16,   290] loss: 1277.428, speed: 27.43, accuracy: 98.73 %\n",
      "[16,   300] loss: 1306.601, speed: 27.41, accuracy: 98.75 %\n",
      "[16,   310] loss: 1361.201, speed: 27.42, accuracy: 98.73 %\n",
      "[16,   320] loss: 1387.954, speed: 27.41, accuracy: 98.73 %\n",
      "[16,   330] loss: 1437.253, speed: 27.42, accuracy: 98.72 %\n",
      "[16,   340] loss: 1498.887, speed: 27.44, accuracy: 98.71 %\n",
      "[16,   350] loss: 1570.715, speed: 27.44, accuracy: 98.69 %\n",
      "[16,   360] loss: 1609.952, speed: 27.46, accuracy: 98.68 %\n",
      "[16,   370] loss: 1662.665, speed: 27.46, accuracy: 98.67 %\n",
      "[16,   380] loss: 1708.026, speed: 27.45, accuracy: 98.68 %\n",
      "[16,   390] loss: 1739.794, speed: 27.47, accuracy: 98.68 %\n",
      "[16,   400] loss: 1780.346, speed: 27.48, accuracy: 98.67 %\n",
      "[16,   410] loss: 1848.519, speed: 27.48, accuracy: 98.65 %\n",
      "[16,   420] loss: 1940.793, speed: 27.47, accuracy: 98.64 %\n",
      "[16,   430] loss: 1980.976, speed: 27.47, accuracy: 98.64 %\n",
      "[16,   440] loss: 2018.074, speed: 27.46, accuracy: 98.65 %\n",
      "[16,   450] loss: 2083.734, speed: 27.46, accuracy: 98.63 %\n",
      "[16,   460] loss: 2160.796, speed: 27.48, accuracy: 98.59 %\n",
      "[16,   470] loss: 2211.307, speed: 27.48, accuracy: 98.59 %\n",
      "[16,   480] loss: 2286.820, speed: 27.47, accuracy: 98.58 %\n",
      "[16,   490] loss: 2340.351, speed: 27.48, accuracy: 98.57 %\n",
      "[16,   500] loss: 2418.381, speed: 27.49, accuracy: 98.56 %\n",
      "[16,   510] loss: 2474.312, speed: 27.48, accuracy: 98.56 %\n",
      "[16,   520] loss: 2553.425, speed: 27.50, accuracy: 98.55 %\n",
      "[16,   530] loss: 2626.939, speed: 27.50, accuracy: 98.54 %\n",
      "[16,   540] loss: 2712.302, speed: 27.51, accuracy: 98.52 %\n",
      "[16,   550] loss: 2780.636, speed: 27.51, accuracy: 98.51 %\n",
      "[16,   560] loss: 2850.972, speed: 27.51, accuracy: 98.50 %\n",
      "[16,   570] loss: 2931.201, speed: 27.52, accuracy: 98.49 %\n",
      "[16,   580] loss: 2961.860, speed: 27.52, accuracy: 98.50 %\n",
      "[16,   590] loss: 3003.551, speed: 27.52, accuracy: 98.51 %\n",
      "[17,     0] loss: 1.147, speed: 25.64, accuracy: 100.00 %\n",
      "[17,    10] loss: 63.081, speed: 27.30, accuracy: 98.36 %\n",
      "[17,    20] loss: 96.723, speed: 27.38, accuracy: 98.71 %\n",
      "[17,    30] loss: 150.707, speed: 27.56, accuracy: 98.55 %\n",
      "[17,    40] loss: 182.070, speed: 27.63, accuracy: 98.61 %\n",
      "[17,    50] loss: 242.765, speed: 27.75, accuracy: 98.53 %\n",
      "[17,    60] loss: 289.644, speed: 27.71, accuracy: 98.52 %\n",
      "[17,    70] loss: 330.006, speed: 27.69, accuracy: 98.49 %\n",
      "[17,    80] loss: 367.458, speed: 27.69, accuracy: 98.53 %\n",
      "[17,    90] loss: 409.206, speed: 27.66, accuracy: 98.56 %\n",
      "[17,   100] loss: 462.615, speed: 27.68, accuracy: 98.52 %\n",
      "[17,   110] loss: 526.561, speed: 27.70, accuracy: 98.52 %\n",
      "[17,   120] loss: 572.311, speed: 27.74, accuracy: 98.50 %\n",
      "[17,   130] loss: 605.924, speed: 27.72, accuracy: 98.53 %\n",
      "[17,   140] loss: 650.149, speed: 27.74, accuracy: 98.52 %\n",
      "[17,   150] loss: 682.196, speed: 27.70, accuracy: 98.58 %\n",
      "[17,   160] loss: 721.885, speed: 27.71, accuracy: 98.58 %\n",
      "[17,   170] loss: 750.663, speed: 27.72, accuracy: 98.60 %\n",
      "[17,   180] loss: 825.555, speed: 27.69, accuracy: 98.56 %\n",
      "[17,   190] loss: 877.103, speed: 27.69, accuracy: 98.55 %\n",
      "[17,   200] loss: 957.584, speed: 27.69, accuracy: 98.50 %\n",
      "[17,   210] loss: 1005.891, speed: 27.71, accuracy: 98.51 %\n",
      "[17,   220] loss: 1071.306, speed: 27.72, accuracy: 98.48 %\n",
      "[17,   230] loss: 1128.883, speed: 27.70, accuracy: 98.48 %\n",
      "[17,   240] loss: 1168.301, speed: 27.67, accuracy: 98.48 %\n",
      "[17,   250] loss: 1209.909, speed: 27.68, accuracy: 98.48 %\n",
      "[17,   260] loss: 1254.442, speed: 27.67, accuracy: 98.49 %\n",
      "[17,   270] loss: 1343.242, speed: 27.69, accuracy: 98.48 %\n",
      "[17,   280] loss: 1387.583, speed: 27.67, accuracy: 98.48 %\n",
      "[17,   290] loss: 1443.349, speed: 27.65, accuracy: 98.48 %\n",
      "[17,   300] loss: 1515.642, speed: 27.65, accuracy: 98.47 %\n",
      "[17,   310] loss: 1548.187, speed: 27.64, accuracy: 98.48 %\n",
      "[17,   320] loss: 1610.824, speed: 27.64, accuracy: 98.47 %\n",
      "[17,   330] loss: 1652.751, speed: 27.66, accuracy: 98.47 %\n",
      "[17,   340] loss: 1689.165, speed: 27.65, accuracy: 98.49 %\n",
      "[17,   350] loss: 1773.731, speed: 27.64, accuracy: 98.48 %\n",
      "[17,   360] loss: 1829.813, speed: 27.63, accuracy: 98.47 %\n",
      "[17,   370] loss: 1872.713, speed: 27.64, accuracy: 98.47 %\n",
      "[17,   380] loss: 1936.506, speed: 27.63, accuracy: 98.47 %\n",
      "[17,   390] loss: 1994.711, speed: 27.61, accuracy: 98.45 %\n",
      "[17,   400] loss: 2047.150, speed: 27.61, accuracy: 98.44 %\n",
      "[17,   410] loss: 2089.290, speed: 27.59, accuracy: 98.46 %\n",
      "[17,   420] loss: 2186.894, speed: 27.58, accuracy: 98.45 %\n",
      "[17,   430] loss: 2236.561, speed: 27.58, accuracy: 98.46 %\n",
      "[17,   440] loss: 2288.941, speed: 27.57, accuracy: 98.46 %\n",
      "[17,   450] loss: 2333.537, speed: 27.57, accuracy: 98.47 %\n",
      "[17,   460] loss: 2377.760, speed: 27.58, accuracy: 98.47 %\n",
      "[17,   470] loss: 2431.248, speed: 27.56, accuracy: 98.46 %\n",
      "[17,   480] loss: 2480.093, speed: 27.56, accuracy: 98.47 %\n",
      "[17,   490] loss: 2573.616, speed: 27.55, accuracy: 98.45 %\n",
      "[17,   500] loss: 2608.516, speed: 27.56, accuracy: 98.46 %\n",
      "[17,   510] loss: 2687.772, speed: 27.56, accuracy: 98.45 %\n",
      "[17,   520] loss: 2760.364, speed: 27.56, accuracy: 98.44 %\n",
      "[17,   530] loss: 2797.617, speed: 27.56, accuracy: 98.44 %\n",
      "[17,   540] loss: 2849.802, speed: 27.57, accuracy: 98.44 %\n",
      "[17,   550] loss: 2902.980, speed: 27.56, accuracy: 98.44 %\n",
      "[17,   560] loss: 2944.417, speed: 27.57, accuracy: 98.45 %\n",
      "[17,   570] loss: 3020.843, speed: 27.57, accuracy: 98.44 %\n",
      "[17,   580] loss: 3083.752, speed: 27.57, accuracy: 98.43 %\n",
      "[17,   590] loss: 3132.447, speed: 27.57, accuracy: 98.42 %\n",
      "[18,     0] loss: 17.916, speed: 27.78, accuracy: 98.00 %\n",
      "[18,    10] loss: 55.190, speed: 27.43, accuracy: 98.82 %\n",
      "[18,    20] loss: 96.494, speed: 27.34, accuracy: 98.71 %\n",
      "[18,    30] loss: 123.528, speed: 27.41, accuracy: 98.71 %\n",
      "[18,    40] loss: 161.004, speed: 27.50, accuracy: 98.80 %\n",
      "[18,    50] loss: 203.692, speed: 27.48, accuracy: 98.82 %\n",
      "[18,    60] loss: 242.072, speed: 27.51, accuracy: 98.74 %\n",
      "[18,    70] loss: 264.936, speed: 27.43, accuracy: 98.82 %\n",
      "[18,    80] loss: 289.818, speed: 27.38, accuracy: 98.84 %\n",
      "[18,    90] loss: 317.536, speed: 27.41, accuracy: 98.89 %\n",
      "[18,   100] loss: 354.661, speed: 27.45, accuracy: 98.90 %\n",
      "[18,   110] loss: 393.127, speed: 27.47, accuracy: 98.87 %\n",
      "[18,   120] loss: 437.774, speed: 27.54, accuracy: 98.83 %\n",
      "[18,   130] loss: 500.865, speed: 27.50, accuracy: 98.77 %\n",
      "[18,   140] loss: 533.539, speed: 27.52, accuracy: 98.77 %\n",
      "[18,   150] loss: 573.900, speed: 27.51, accuracy: 98.74 %\n",
      "[18,   160] loss: 601.599, speed: 27.51, accuracy: 98.76 %\n",
      "[18,   170] loss: 661.800, speed: 27.56, accuracy: 98.75 %\n",
      "[18,   180] loss: 734.705, speed: 27.57, accuracy: 98.71 %\n",
      "[18,   190] loss: 762.195, speed: 27.57, accuracy: 98.73 %\n",
      "[18,   200] loss: 788.305, speed: 27.56, accuracy: 98.75 %\n",
      "[18,   210] loss: 828.812, speed: 27.54, accuracy: 98.75 %\n",
      "[18,   220] loss: 861.146, speed: 27.51, accuracy: 98.76 %\n",
      "[18,   230] loss: 908.706, speed: 27.50, accuracy: 98.74 %\n",
      "[18,   240] loss: 957.057, speed: 27.51, accuracy: 98.72 %\n",
      "[18,   250] loss: 994.902, speed: 27.52, accuracy: 98.72 %\n",
      "[18,   260] loss: 1034.637, speed: 27.51, accuracy: 98.74 %\n",
      "[18,   270] loss: 1076.226, speed: 27.48, accuracy: 98.72 %\n",
      "[18,   280] loss: 1130.978, speed: 27.47, accuracy: 98.72 %\n",
      "[18,   290] loss: 1199.615, speed: 27.48, accuracy: 98.70 %\n",
      "[18,   300] loss: 1221.197, speed: 27.48, accuracy: 98.72 %\n",
      "[18,   310] loss: 1262.879, speed: 27.49, accuracy: 98.72 %\n",
      "[18,   320] loss: 1316.161, speed: 27.48, accuracy: 98.72 %\n",
      "[18,   330] loss: 1375.978, speed: 27.48, accuracy: 98.70 %\n",
      "[18,   340] loss: 1421.908, speed: 27.47, accuracy: 98.71 %\n",
      "[18,   350] loss: 1475.595, speed: 27.49, accuracy: 98.70 %\n",
      "[18,   360] loss: 1524.764, speed: 27.49, accuracy: 98.70 %\n",
      "[18,   370] loss: 1541.720, speed: 27.50, accuracy: 98.71 %\n",
      "[18,   380] loss: 1595.634, speed: 27.51, accuracy: 98.71 %\n",
      "[18,   390] loss: 1657.598, speed: 27.49, accuracy: 98.69 %\n",
      "[18,   400] loss: 1698.660, speed: 27.49, accuracy: 98.70 %\n",
      "[18,   410] loss: 1777.824, speed: 27.49, accuracy: 98.69 %\n",
      "[18,   420] loss: 1835.910, speed: 27.51, accuracy: 98.68 %\n",
      "[18,   430] loss: 1921.989, speed: 27.53, accuracy: 98.67 %\n",
      "[18,   440] loss: 1985.286, speed: 27.54, accuracy: 98.66 %\n",
      "[18,   450] loss: 2042.019, speed: 27.54, accuracy: 98.66 %\n",
      "[18,   460] loss: 2109.943, speed: 27.54, accuracy: 98.65 %\n",
      "[18,   470] loss: 2164.239, speed: 27.55, accuracy: 98.64 %\n",
      "[18,   480] loss: 2195.227, speed: 27.54, accuracy: 98.64 %\n",
      "[18,   490] loss: 2232.916, speed: 27.54, accuracy: 98.65 %\n",
      "[18,   500] loss: 2305.584, speed: 27.52, accuracy: 98.64 %\n",
      "[18,   510] loss: 2366.202, speed: 27.52, accuracy: 98.64 %\n",
      "[18,   520] loss: 2424.520, speed: 27.51, accuracy: 98.63 %\n",
      "[18,   530] loss: 2454.520, speed: 27.52, accuracy: 98.64 %\n",
      "[18,   540] loss: 2494.399, speed: 27.53, accuracy: 98.64 %\n",
      "[18,   550] loss: 2535.146, speed: 27.53, accuracy: 98.64 %\n",
      "[18,   560] loss: 2618.311, speed: 27.54, accuracy: 98.63 %\n",
      "[18,   570] loss: 2654.113, speed: 27.52, accuracy: 98.62 %\n",
      "[18,   580] loss: 2717.495, speed: 27.51, accuracy: 98.61 %\n",
      "[18,   590] loss: 2760.851, speed: 27.51, accuracy: 98.61 %\n",
      "[19,     0] loss: 7.728, speed: 25.64, accuracy: 98.00 %\n",
      "[19,    10] loss: 45.037, speed: 27.50, accuracy: 98.64 %\n",
      "[19,    20] loss: 69.078, speed: 27.93, accuracy: 98.95 %\n",
      "[19,    30] loss: 97.580, speed: 27.80, accuracy: 99.06 %\n",
      "[19,    40] loss: 131.656, speed: 27.64, accuracy: 99.00 %\n",
      "[19,    50] loss: 166.267, speed: 27.63, accuracy: 98.94 %\n",
      "[19,    60] loss: 197.089, speed: 27.61, accuracy: 98.90 %\n",
      "[19,    70] loss: 241.023, speed: 27.55, accuracy: 98.90 %\n",
      "[19,    80] loss: 274.966, speed: 27.63, accuracy: 98.91 %\n",
      "[19,    90] loss: 304.712, speed: 27.61, accuracy: 98.93 %\n",
      "[19,   100] loss: 333.703, speed: 27.59, accuracy: 98.96 %\n",
      "[19,   110] loss: 371.764, speed: 27.61, accuracy: 98.93 %\n",
      "[19,   120] loss: 411.938, speed: 27.64, accuracy: 98.93 %\n",
      "[19,   130] loss: 453.432, speed: 27.67, accuracy: 98.91 %\n",
      "[19,   140] loss: 490.686, speed: 27.61, accuracy: 98.94 %\n",
      "[19,   150] loss: 521.235, speed: 27.62, accuracy: 98.94 %\n",
      "[19,   160] loss: 553.131, speed: 27.62, accuracy: 98.96 %\n",
      "[19,   170] loss: 582.518, speed: 27.62, accuracy: 98.98 %\n",
      "[19,   180] loss: 626.959, speed: 27.62, accuracy: 98.97 %\n",
      "[19,   190] loss: 666.934, speed: 27.63, accuracy: 98.96 %\n",
      "[19,   200] loss: 703.781, speed: 27.62, accuracy: 98.96 %\n",
      "[19,   210] loss: 735.260, speed: 27.63, accuracy: 98.96 %\n",
      "[19,   220] loss: 780.848, speed: 27.64, accuracy: 98.91 %\n",
      "[19,   230] loss: 819.026, speed: 27.63, accuracy: 98.90 %\n",
      "[19,   240] loss: 868.637, speed: 27.60, accuracy: 98.88 %\n",
      "[19,   250] loss: 925.968, speed: 27.62, accuracy: 98.85 %\n",
      "[19,   260] loss: 968.040, speed: 27.59, accuracy: 98.84 %\n",
      "[19,   270] loss: 1016.926, speed: 27.55, accuracy: 98.84 %\n",
      "[19,   280] loss: 1055.951, speed: 27.55, accuracy: 98.83 %\n",
      "[19,   290] loss: 1112.953, speed: 27.54, accuracy: 98.82 %\n",
      "[19,   300] loss: 1209.363, speed: 27.53, accuracy: 98.79 %\n",
      "[19,   310] loss: 1245.075, speed: 27.52, accuracy: 98.78 %\n",
      "[19,   320] loss: 1299.409, speed: 27.52, accuracy: 98.78 %\n",
      "[19,   330] loss: 1336.978, speed: 27.53, accuracy: 98.78 %\n",
      "[19,   340] loss: 1373.570, speed: 27.52, accuracy: 98.80 %\n",
      "[19,   350] loss: 1444.252, speed: 27.52, accuracy: 98.79 %\n",
      "[19,   360] loss: 1483.925, speed: 27.54, accuracy: 98.78 %\n",
      "[19,   370] loss: 1546.483, speed: 27.52, accuracy: 98.75 %\n",
      "[19,   380] loss: 1611.417, speed: 27.51, accuracy: 98.74 %\n",
      "[19,   390] loss: 1670.241, speed: 27.50, accuracy: 98.74 %\n",
      "[19,   400] loss: 1713.945, speed: 27.48, accuracy: 98.74 %\n",
      "[19,   410] loss: 1761.727, speed: 27.48, accuracy: 98.74 %\n",
      "[19,   420] loss: 1832.997, speed: 27.49, accuracy: 98.73 %\n",
      "[19,   430] loss: 1890.669, speed: 27.48, accuracy: 98.71 %\n",
      "[19,   440] loss: 1965.542, speed: 27.48, accuracy: 98.70 %\n",
      "[19,   450] loss: 2028.362, speed: 27.47, accuracy: 98.69 %\n",
      "[19,   460] loss: 2065.248, speed: 27.48, accuracy: 98.68 %\n",
      "[19,   470] loss: 2121.100, speed: 27.47, accuracy: 98.67 %\n",
      "[19,   480] loss: 2172.753, speed: 27.47, accuracy: 98.66 %\n",
      "[19,   490] loss: 2243.135, speed: 27.46, accuracy: 98.64 %\n",
      "[19,   500] loss: 2310.792, speed: 27.47, accuracy: 98.64 %\n",
      "[19,   510] loss: 2378.000, speed: 27.46, accuracy: 98.64 %\n",
      "[19,   520] loss: 2423.789, speed: 27.46, accuracy: 98.64 %\n",
      "[19,   530] loss: 2465.571, speed: 27.46, accuracy: 98.64 %\n",
      "[19,   540] loss: 2528.238, speed: 27.47, accuracy: 98.63 %\n",
      "[19,   550] loss: 2586.906, speed: 27.47, accuracy: 98.62 %\n",
      "[19,   560] loss: 2639.887, speed: 27.48, accuracy: 98.62 %\n",
      "[19,   570] loss: 2710.966, speed: 27.48, accuracy: 98.62 %\n",
      "[19,   580] loss: 2749.402, speed: 27.49, accuracy: 98.62 %\n",
      "[19,   590] loss: 2812.742, speed: 27.49, accuracy: 98.61 %\n",
      "[20,     0] loss: 11.183, speed: 28.57, accuracy: 95.00 %\n",
      "[20,    10] loss: 52.841, speed: 27.16, accuracy: 98.27 %\n",
      "[20,    20] loss: 79.946, speed: 27.03, accuracy: 98.57 %\n",
      "[20,    30] loss: 118.658, speed: 27.31, accuracy: 98.58 %\n",
      "[20,    40] loss: 142.629, speed: 27.57, accuracy: 98.71 %\n",
      "[20,    50] loss: 160.600, speed: 27.54, accuracy: 98.86 %\n",
      "[20,    60] loss: 225.426, speed: 27.50, accuracy: 98.79 %\n",
      "[20,    70] loss: 257.134, speed: 27.43, accuracy: 98.82 %\n",
      "[20,    80] loss: 294.802, speed: 27.52, accuracy: 98.79 %\n",
      "[20,    90] loss: 320.040, speed: 27.51, accuracy: 98.80 %\n",
      "[20,   100] loss: 355.372, speed: 27.57, accuracy: 98.79 %\n",
      "[20,   110] loss: 402.830, speed: 27.55, accuracy: 98.77 %\n",
      "[20,   120] loss: 454.977, speed: 27.56, accuracy: 98.69 %\n",
      "[20,   130] loss: 493.088, speed: 27.56, accuracy: 98.67 %\n",
      "[20,   140] loss: 543.247, speed: 27.60, accuracy: 98.66 %\n",
      "[20,   150] loss: 602.098, speed: 27.57, accuracy: 98.63 %\n",
      "[20,   160] loss: 646.832, speed: 27.59, accuracy: 98.65 %\n",
      "[20,   170] loss: 694.545, speed: 27.55, accuracy: 98.63 %\n",
      "[20,   180] loss: 742.709, speed: 27.52, accuracy: 98.61 %\n",
      "[20,   190] loss: 797.176, speed: 27.53, accuracy: 98.61 %\n",
      "[20,   200] loss: 834.578, speed: 27.54, accuracy: 98.61 %\n",
      "[20,   210] loss: 888.313, speed: 27.49, accuracy: 98.63 %\n",
      "[20,   220] loss: 944.999, speed: 27.48, accuracy: 98.61 %\n",
      "[20,   230] loss: 997.293, speed: 27.48, accuracy: 98.60 %\n",
      "[20,   240] loss: 1068.712, speed: 27.40, accuracy: 98.59 %\n",
      "[20,   250] loss: 1121.019, speed: 27.40, accuracy: 98.58 %\n",
      "[20,   260] loss: 1149.517, speed: 27.41, accuracy: 98.60 %\n",
      "[20,   270] loss: 1197.099, speed: 27.42, accuracy: 98.61 %\n",
      "[20,   280] loss: 1234.497, speed: 27.45, accuracy: 98.62 %\n",
      "[20,   290] loss: 1295.139, speed: 27.46, accuracy: 98.61 %\n",
      "[20,   300] loss: 1335.116, speed: 27.44, accuracy: 98.61 %\n",
      "[20,   310] loss: 1390.925, speed: 27.46, accuracy: 98.60 %\n",
      "[20,   320] loss: 1435.655, speed: 27.45, accuracy: 98.60 %\n",
      "[20,   330] loss: 1463.402, speed: 27.45, accuracy: 98.61 %\n",
      "[20,   340] loss: 1508.868, speed: 27.47, accuracy: 98.61 %\n",
      "[20,   350] loss: 1578.442, speed: 27.48, accuracy: 98.61 %\n",
      "[20,   360] loss: 1608.616, speed: 27.48, accuracy: 98.61 %\n",
      "[20,   370] loss: 1661.022, speed: 27.49, accuracy: 98.60 %\n",
      "[20,   380] loss: 1700.814, speed: 27.50, accuracy: 98.60 %\n",
      "[20,   390] loss: 1748.525, speed: 27.48, accuracy: 98.61 %\n",
      "[20,   400] loss: 1810.692, speed: 27.48, accuracy: 98.60 %\n",
      "[20,   410] loss: 1870.345, speed: 27.49, accuracy: 98.59 %\n",
      "[20,   420] loss: 1937.956, speed: 27.48, accuracy: 98.58 %\n",
      "[20,   430] loss: 2012.567, speed: 27.49, accuracy: 98.56 %\n",
      "[20,   440] loss: 2059.878, speed: 27.48, accuracy: 98.56 %\n",
      "[20,   450] loss: 2104.337, speed: 27.47, accuracy: 98.56 %\n",
      "[20,   460] loss: 2146.754, speed: 27.48, accuracy: 98.56 %\n",
      "[20,   470] loss: 2183.941, speed: 27.49, accuracy: 98.57 %\n",
      "[20,   480] loss: 2249.239, speed: 27.48, accuracy: 98.56 %\n",
      "[20,   490] loss: 2301.131, speed: 27.46, accuracy: 98.55 %\n",
      "[20,   500] loss: 2357.188, speed: 27.47, accuracy: 98.54 %\n",
      "[20,   510] loss: 2445.827, speed: 27.47, accuracy: 98.52 %\n",
      "[20,   520] loss: 2488.869, speed: 27.47, accuracy: 98.51 %\n",
      "[20,   530] loss: 2538.031, speed: 27.47, accuracy: 98.51 %\n",
      "[20,   540] loss: 2602.770, speed: 27.47, accuracy: 98.50 %\n",
      "[20,   550] loss: 2651.765, speed: 27.48, accuracy: 98.50 %\n",
      "[20,   560] loss: 2703.266, speed: 27.49, accuracy: 98.49 %\n",
      "[20,   570] loss: 2795.104, speed: 27.48, accuracy: 98.46 %\n",
      "[20,   580] loss: 2858.388, speed: 27.48, accuracy: 98.45 %\n",
      "[20,   590] loss: 2929.934, speed: 27.47, accuracy: 98.45 %\n"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class trainModel():\n",
    "    def __init__(self):\n",
    "        self.train_loss = 0.0\n",
    "        self.total = 0\n",
    "        self.correct = 0\n",
    "        self.start_time = 0\n",
    "        self.trainLossArray = []\n",
    "        self.TrainAccuracyArray = []\n",
    "        self.epochArray = []\n",
    "\n",
    "    def updateModel(self, data):\n",
    "        # deconstructing input\n",
    "        inputs = data[0]\n",
    "        labels = data[1]\n",
    "\n",
    "        # Forward Pass\n",
    "        output = predictionModel(Variable(inputs))\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        # Find the Loss\n",
    "        loss = criterion(output[0],labels)\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate Loss\n",
    "        self.train_loss +=loss.item() * labels.size(0)\n",
    "\n",
    "        _, predicted = torch.max(output[0], 1)\n",
    "        self.total += labels.size(0)\n",
    "        self.correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * self.correct / self.total\n",
    "        return accuracy, predicted\n",
    "\n",
    "    def training(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            self.train_loss = 0.0\n",
    "            self.total = 0\n",
    "            self.correct = 0\n",
    "            self.start_time = time.time()\n",
    "            for i, data in enumerate(trainloader):\n",
    "                # train and update model\n",
    "                accuracy, predicted = self.updateModel(data)\n",
    "\n",
    "                # print every 10 batches\n",
    "                if i % 10 == 0:    \n",
    "                    batch_time = time.time()\n",
    "                    speed = (i+1)/(batch_time-self.start_time)\n",
    "                    print('[%d, %5d] loss: %.3f, speed: %.2f, accuracy: %.2f %%' % (epoch + 1, i, self.train_loss, speed, accuracy))\n",
    "\n",
    "            predictionModel.eval()    \n",
    "            self.TrainAccuracyArray.append(accuracy)\n",
    "            self.trainLossArray.append(self.train_loss)\n",
    "            self.epochArray.append(epoch)\n",
    "        return\n",
    "\n",
    "    def graphs(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        # plot the training graphs\n",
    "        figure, axis = plt.subplots(2, 2)\n",
    "        axis[0,0].plot(self.epochArray,self.trainLossArray)\n",
    "        axis[0,0].set_title(\"Training Loss\")\n",
    "\n",
    "\n",
    "        axis[1,0].plot(self.epochArray,self.TrainAccuracyArray)\n",
    "        axis[1,0].set_title(\"Training Accuracy\")\n",
    "\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "# Training parameters\n",
    "epochs = 20\n",
    "model = trainModel()\n",
    "model.training(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.0631, Accuracy: 10.5200\n",
      "tensor([6, 5, 4, 9, 9, 9, 1, 6, 6, 4, 5, 7, 3, 2, 5, 2, 1, 4, 3, 7, 2, 2, 4, 6,\n",
      "        1, 9, 8, 3, 6, 2, 4, 7, 3, 4, 4, 3, 9, 9, 8, 5, 3, 7, 9, 2, 1, 6, 8, 5,\n",
      "        0, 0, 8, 4, 5, 7, 0, 4, 9, 6, 4, 8, 8, 6, 7, 0, 9, 1, 6, 8, 7, 5, 0, 3,\n",
      "        9, 1, 9, 2, 1, 9, 8, 1, 5, 3, 9, 7, 4, 8, 7, 9, 0, 1, 9, 5, 7, 8, 0, 6,\n",
      "        1, 0, 5, 9])\n",
      "Epoch [1/10], Step [200/600], Loss: 0.0168, Accuracy: 11.6600\n",
      "tensor([6, 8, 5, 6, 5, 6, 8, 9, 6, 6, 7, 1, 3, 8, 4, 4, 9, 5, 2, 6, 0, 6, 1, 3,\n",
      "        6, 1, 3, 4, 9, 3, 8, 7, 7, 3, 6, 8, 5, 8, 1, 3, 9, 8, 7, 6, 0, 2, 2, 1,\n",
      "        1, 5, 7, 0, 2, 2, 3, 3, 7, 3, 9, 8, 7, 4, 0, 3, 2, 7, 2, 8, 1, 2, 2, 2,\n",
      "        4, 3, 3, 8, 2, 7, 6, 7, 2, 9, 2, 6, 6, 6, 8, 3, 1, 3, 1, 2, 6, 7, 7, 6,\n",
      "        1, 2, 9, 0])\n",
      "Epoch [1/10], Step [300/600], Loss: 0.0233, Accuracy: 10.5800\n",
      "tensor([3, 1, 3, 5, 5, 7, 5, 4, 5, 0, 5, 0, 0, 3, 0, 8, 7, 2, 2, 0, 8, 6, 8, 2,\n",
      "        2, 7, 3, 1, 3, 0, 1, 3, 1, 9, 3, 3, 8, 3, 5, 6, 2, 1, 6, 5, 1, 3, 6, 3,\n",
      "        8, 0, 2, 0, 7, 9, 4, 5, 9, 2, 7, 5, 2, 2, 6, 5, 9, 1, 3, 8, 9, 6, 6, 2,\n",
      "        2, 4, 9, 5, 5, 5, 3, 3, 4, 7, 6, 8, 4, 6, 4, 2, 1, 4, 4, 4, 1, 6, 2, 7,\n",
      "        8, 7, 8, 7])\n",
      "Epoch [1/10], Step [400/600], Loss: 0.1022, Accuracy: 10.9400\n",
      "tensor([4, 0, 0, 2, 2, 5, 0, 7, 3, 7, 1, 5, 8, 3, 9, 8, 1, 2, 2, 3, 9, 9, 8, 0,\n",
      "        7, 1, 4, 7, 5, 5, 4, 6, 2, 8, 9, 8, 5, 3, 5, 3, 4, 0, 2, 3, 3, 5, 9, 8,\n",
      "        4, 5, 7, 7, 9, 6, 3, 5, 8, 5, 9, 5, 5, 7, 9, 8, 6, 4, 5, 6, 6, 3, 1, 4,\n",
      "        7, 6, 9, 3, 4, 1, 2, 5, 5, 4, 0, 2, 5, 0, 4, 6, 7, 1, 3, 1, 1, 4, 9, 4,\n",
      "        1, 5, 9, 5])\n",
      "Epoch [1/10], Step [500/600], Loss: 0.0030, Accuracy: 10.3600\n",
      "tensor([3, 2, 2, 6, 2, 9, 3, 6, 7, 5, 0, 2, 1, 8, 2, 6, 5, 6, 6, 3, 7, 3, 9, 8,\n",
      "        7, 7, 1, 4, 6, 7, 9, 6, 0, 5, 0, 7, 5, 4, 5, 4, 3, 1, 2, 3, 8, 7, 5, 0,\n",
      "        3, 2, 5, 4, 6, 5, 0, 9, 2, 0, 1, 8, 5, 5, 1, 2, 4, 0, 8, 3, 0, 4, 6, 3,\n",
      "        6, 7, 4, 1, 8, 7, 4, 6, 7, 4, 7, 5, 5, 4, 0, 3, 8, 1, 9, 7, 7, 0, 8, 9,\n",
      "        4, 1, 9, 6])\n",
      "Epoch [1/10], Step [600/600], Loss: 0.0774, Accuracy: 10.4500\n",
      "tensor([6, 3, 5, 2, 7, 7, 1, 5, 0, 1, 7, 2, 9, 5, 3, 4, 3, 0, 8, 1, 0, 2, 3, 6,\n",
      "        9, 8, 9, 7, 7, 5, 1, 9, 6, 9, 6, 9, 5, 1, 4, 2, 7, 8, 0, 1, 1, 1, 7, 8,\n",
      "        0, 5, 5, 5, 6, 4, 4, 5, 4, 3, 5, 5, 0, 5, 2, 1, 8, 9, 8, 1, 3, 7, 4, 8,\n",
      "        0, 5, 0, 1, 8, 2, 6, 7, 7, 5, 3, 2, 8, 1, 2, 3, 6, 9, 3, 9, 3, 9, 6, 7,\n",
      "        5, 0, 3, 1])\n",
      "Epoch [2/10], Step [100/600], Loss: 0.0183, Accuracy: 10.6500\n",
      "tensor([0, 3, 1, 9, 8, 0, 5, 7, 7, 2, 8, 2, 2, 0, 4, 6, 2, 8, 3, 1, 5, 2, 1, 1,\n",
      "        0, 8, 5, 6, 6, 6, 9, 6, 3, 9, 8, 5, 7, 8, 5, 4, 8, 2, 6, 4, 7, 1, 9, 6,\n",
      "        5, 4, 0, 7, 8, 5, 2, 2, 1, 0, 8, 0, 6, 7, 3, 7, 1, 4, 8, 7, 7, 9, 3, 5,\n",
      "        2, 7, 6, 6, 4, 0, 8, 9, 6, 7, 1, 7, 1, 1, 0, 5, 9, 5, 0, 1, 1, 0, 0, 4,\n",
      "        0, 5, 4, 7])\n",
      "Epoch [2/10], Step [200/600], Loss: 0.0052, Accuracy: 11.2400\n",
      "tensor([7, 8, 8, 8, 3, 6, 0, 6, 6, 5, 1, 1, 2, 0, 0, 7, 8, 8, 8, 5, 9, 5, 9, 3,\n",
      "        8, 7, 2, 3, 7, 3, 4, 6, 6, 3, 6, 3, 2, 8, 5, 9, 6, 4, 1, 4, 3, 1, 1, 8,\n",
      "        5, 0, 4, 8, 6, 7, 3, 9, 8, 6, 9, 2, 2, 4, 9, 3, 7, 5, 3, 9, 2, 3, 0, 4,\n",
      "        9, 3, 6, 2, 3, 7, 7, 9, 2, 9, 1, 3, 8, 5, 8, 2, 9, 6, 2, 8, 8, 1, 5, 6,\n",
      "        1, 3, 3, 6])\n",
      "Epoch [2/10], Step [300/600], Loss: 0.0305, Accuracy: 11.6200\n",
      "tensor([8, 8, 1, 1, 1, 9, 9, 8, 2, 8, 1, 6, 8, 3, 1, 0, 1, 0, 2, 7, 2, 1, 8, 1,\n",
      "        1, 6, 7, 4, 1, 7, 2, 2, 4, 4, 1, 4, 4, 3, 4, 5, 7, 8, 7, 4, 7, 1, 4, 3,\n",
      "        7, 8, 5, 7, 8, 1, 9, 4, 8, 3, 0, 9, 2, 4, 3, 3, 2, 2, 6, 0, 1, 6, 0, 8,\n",
      "        7, 9, 2, 4, 7, 7, 4, 2, 6, 7, 3, 4, 3, 7, 3, 2, 6, 6, 3, 4, 6, 5, 2, 2,\n",
      "        4, 3, 9, 7])\n",
      "Epoch [2/10], Step [400/600], Loss: 0.0345, Accuracy: 11.6500\n",
      "tensor([4, 0, 3, 8, 1, 8, 1, 1, 4, 7, 7, 2, 6, 5, 0, 7, 8, 6, 7, 7, 5, 4, 8, 9,\n",
      "        5, 0, 7, 6, 0, 0, 7, 9, 0, 8, 4, 6, 0, 3, 0, 9, 8, 4, 7, 8, 2, 3, 6, 3,\n",
      "        7, 3, 4, 8, 1, 2, 0, 3, 3, 6, 6, 8, 6, 7, 0, 8, 4, 8, 6, 9, 9, 6, 6, 4,\n",
      "        7, 2, 8, 6, 8, 5, 9, 1, 0, 4, 4, 7, 4, 2, 7, 8, 3, 9, 5, 0, 8, 7, 8, 7,\n",
      "        0, 1, 7, 2])\n",
      "Epoch [2/10], Step [500/600], Loss: 0.0130, Accuracy: 10.4800\n",
      "tensor([6, 6, 1, 3, 4, 5, 5, 9, 1, 9, 4, 6, 3, 8, 8, 6, 6, 7, 7, 9, 8, 3, 0, 1,\n",
      "        5, 8, 7, 0, 8, 1, 7, 1, 2, 4, 0, 2, 2, 8, 8, 3, 3, 3, 9, 4, 2, 4, 8, 1,\n",
      "        1, 1, 1, 4, 3, 0, 9, 2, 5, 7, 0, 7, 3, 6, 8, 9, 6, 9, 8, 2, 7, 8, 5, 7,\n",
      "        4, 0, 7, 6, 3, 0, 9, 1, 7, 6, 6, 4, 7, 8, 9, 4, 1, 1, 2, 0, 4, 9, 2, 8,\n",
      "        2, 4, 4, 2])\n",
      "Epoch [2/10], Step [600/600], Loss: 0.1090, Accuracy: 11.2600\n",
      "tensor([5, 2, 8, 3, 5, 8, 3, 9, 0, 7, 2, 5, 0, 2, 9, 5, 6, 2, 0, 7, 1, 3, 9, 8,\n",
      "        9, 7, 5, 4, 7, 2, 9, 1, 2, 5, 5, 4, 1, 1, 9, 0, 5, 5, 1, 8, 7, 9, 0, 3,\n",
      "        0, 6, 4, 5, 9, 0, 8, 8, 0, 2, 0, 2, 6, 3, 0, 1, 5, 1, 3, 5, 3, 9, 3, 7,\n",
      "        3, 2, 4, 7, 3, 9, 4, 0, 2, 9, 3, 9, 4, 2, 4, 3, 2, 3, 6, 4, 7, 2, 2, 4,\n",
      "        2, 9, 4, 4])\n",
      "Epoch [3/10], Step [100/600], Loss: 0.0120, Accuracy: 11.4200\n",
      "tensor([0, 0, 6, 7, 1, 5, 6, 1, 1, 7, 4, 6, 1, 5, 3, 8, 2, 7, 4, 6, 1, 1, 9, 4,\n",
      "        5, 8, 7, 3, 7, 1, 7, 8, 6, 2, 1, 7, 7, 9, 5, 6, 6, 3, 9, 0, 6, 9, 3, 6,\n",
      "        5, 8, 8, 1, 0, 1, 1, 3, 1, 4, 6, 4, 7, 4, 7, 8, 5, 0, 5, 5, 8, 1, 4, 1,\n",
      "        9, 1, 8, 6, 2, 6, 5, 7, 1, 0, 3, 3, 9, 0, 8, 3, 7, 0, 3, 3, 0, 6, 3, 4,\n",
      "        3, 5, 1, 7])\n",
      "Epoch [3/10], Step [200/600], Loss: 0.0669, Accuracy: 11.3100\n",
      "tensor([4, 6, 7, 4, 3, 0, 5, 6, 5, 9, 7, 3, 9, 7, 5, 5, 0, 7, 2, 6, 1, 4, 2, 5,\n",
      "        9, 7, 3, 6, 4, 6, 1, 6, 7, 1, 8, 3, 9, 9, 6, 9, 3, 0, 9, 5, 6, 0, 6, 6,\n",
      "        7, 2, 8, 5, 2, 1, 9, 2, 6, 7, 3, 9, 7, 2, 9, 9, 5, 4, 3, 4, 9, 8, 7, 9,\n",
      "        9, 5, 8, 1, 3, 0, 1, 5, 6, 8, 1, 1, 7, 5, 3, 6, 0, 5, 6, 7, 6, 0, 3, 3,\n",
      "        9, 6, 2, 1])\n",
      "Epoch [3/10], Step [300/600], Loss: 0.0053, Accuracy: 10.4400\n",
      "tensor([8, 1, 3, 8, 8, 1, 9, 9, 2, 9, 0, 6, 7, 0, 2, 4, 2, 3, 7, 1, 3, 4, 2, 0,\n",
      "        4, 0, 2, 2, 6, 7, 9, 4, 4, 9, 1, 8, 5, 4, 4, 6, 7, 2, 2, 7, 2, 3, 0, 6,\n",
      "        7, 5, 4, 4, 6, 0, 3, 8, 5, 0, 5, 9, 0, 3, 6, 6, 4, 9, 0, 0, 3, 2, 6, 2,\n",
      "        7, 3, 6, 0, 3, 7, 5, 1, 8, 7, 4, 1, 8, 3, 2, 8, 4, 1, 7, 2, 1, 3, 9, 9,\n",
      "        6, 5, 6, 6])\n",
      "Epoch [3/10], Step [400/600], Loss: 0.0312, Accuracy: 10.3200\n",
      "tensor([4, 6, 9, 6, 4, 8, 7, 7, 7, 6, 9, 0, 4, 8, 1, 7, 9, 1, 4, 9, 4, 4, 3, 2,\n",
      "        2, 5, 3, 6, 2, 3, 8, 5, 7, 3, 8, 9, 9, 5, 2, 4, 6, 8, 6, 4, 7, 0, 2, 2,\n",
      "        8, 1, 3, 1, 2, 6, 5, 0, 1, 2, 3, 8, 5, 5, 2, 8, 6, 7, 1, 7, 9, 7, 8, 3,\n",
      "        7, 1, 4, 3, 4, 0, 8, 2, 9, 0, 0, 2, 1, 2, 2, 8, 1, 0, 8, 5, 2, 4, 1, 9,\n",
      "        5, 4, 1, 0])\n",
      "Epoch [3/10], Step [500/600], Loss: 0.0166, Accuracy: 10.9300\n",
      "tensor([1, 5, 1, 7, 8, 0, 1, 2, 2, 7, 7, 9, 1, 5, 4, 8, 7, 5, 9, 3, 0, 3, 7, 0,\n",
      "        1, 4, 8, 4, 9, 2, 8, 7, 1, 2, 0, 5, 5, 9, 1, 2, 7, 5, 0, 7, 4, 4, 2, 3,\n",
      "        2, 2, 9, 2, 4, 8, 7, 5, 1, 7, 7, 5, 5, 0, 5, 6, 3, 3, 8, 4, 6, 5, 9, 2,\n",
      "        6, 1, 4, 1, 2, 3, 5, 8, 1, 7, 8, 8, 2, 1, 5, 6, 8, 4, 6, 2, 2, 6, 9, 3,\n",
      "        7, 9, 4, 5])\n",
      "Epoch [3/10], Step [600/600], Loss: 0.2088, Accuracy: 10.6300\n",
      "tensor([5, 9, 1, 5, 1, 8, 0, 9, 1, 2, 8, 2, 3, 3, 6, 7, 8, 5, 3, 9, 0, 4, 3, 1,\n",
      "        8, 7, 6, 9, 1, 0, 8, 1, 4, 3, 3, 8, 9, 7, 9, 7, 3, 0, 9, 1, 4, 7, 9, 2,\n",
      "        3, 2, 8, 1, 3, 2, 5, 7, 8, 3, 9, 8, 1, 2, 8, 6, 4, 0, 2, 7, 7, 6, 3, 2,\n",
      "        6, 7, 9, 1, 8, 5, 4, 4, 8, 0, 3, 0, 6, 6, 9, 6, 8, 9, 1, 5, 8, 3, 0, 7,\n",
      "        1, 9, 6, 0])\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0005, Accuracy: 10.2400\n",
      "tensor([0, 0, 6, 9, 8, 0, 4, 8, 4, 9, 9, 0, 5, 0, 3, 0, 4, 5, 7, 4, 1, 6, 9, 4,\n",
      "        6, 9, 3, 5, 2, 9, 8, 6, 1, 3, 8, 4, 8, 2, 7, 9, 3, 3, 5, 4, 0, 1, 8, 2,\n",
      "        2, 3, 9, 5, 6, 9, 4, 9, 6, 2, 1, 7, 4, 7, 7, 5, 1, 1, 8, 5, 8, 2, 0, 9,\n",
      "        0, 2, 5, 3, 9, 7, 1, 2, 1, 7, 6, 9, 5, 8, 7, 1, 3, 8, 4, 5, 4, 7, 5, 5,\n",
      "        0, 1, 6, 2])\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0353, Accuracy: 10.4700\n",
      "tensor([9, 3, 9, 2, 0, 4, 7, 1, 4, 3, 6, 4, 4, 2, 9, 1, 4, 0, 0, 6, 7, 1, 0, 0,\n",
      "        7, 7, 6, 7, 1, 8, 0, 5, 9, 4, 9, 5, 3, 2, 4, 9, 8, 1, 9, 5, 8, 8, 6, 0,\n",
      "        4, 8, 3, 1, 7, 8, 0, 3, 7, 1, 8, 1, 6, 2, 9, 8, 4, 2, 2, 7, 9, 8, 8, 1,\n",
      "        2, 5, 0, 3, 4, 5, 9, 3, 3, 4, 7, 7, 4, 3, 8, 6, 6, 4, 8, 5, 6, 5, 3, 1,\n",
      "        3, 9, 9, 4])\n",
      "Epoch [4/10], Step [300/600], Loss: 0.0067, Accuracy: 11.1800\n",
      "tensor([2, 6, 4, 4, 8, 9, 4, 3, 7, 4, 4, 0, 3, 8, 3, 4, 5, 7, 5, 6, 7, 2, 6, 4,\n",
      "        3, 7, 2, 9, 6, 6, 3, 6, 3, 7, 9, 2, 1, 7, 9, 0, 8, 9, 4, 8, 4, 5, 6, 1,\n",
      "        6, 1, 1, 1, 1, 2, 4, 4, 8, 1, 2, 0, 3, 4, 5, 1, 9, 1, 3, 0, 4, 1, 4, 6,\n",
      "        8, 7, 6, 6, 2, 8, 0, 3, 4, 4, 8, 6, 6, 5, 6, 0, 1, 0, 2, 0, 8, 3, 6, 7,\n",
      "        4, 3, 9, 9])\n",
      "Epoch [4/10], Step [400/600], Loss: 0.0075, Accuracy: 10.5400\n",
      "tensor([4, 5, 4, 4, 9, 9, 8, 4, 9, 2, 8, 1, 0, 4, 1, 4, 4, 2, 6, 7, 1, 8, 8, 6,\n",
      "        1, 5, 5, 9, 1, 4, 4, 0, 7, 9, 7, 5, 4, 5, 9, 2, 5, 3, 3, 3, 0, 5, 0, 2,\n",
      "        7, 6, 1, 1, 4, 8, 2, 2, 5, 6, 3, 5, 5, 0, 1, 2, 0, 1, 9, 2, 3, 9, 2, 3,\n",
      "        8, 3, 7, 0, 2, 1, 8, 7, 9, 5, 2, 8, 0, 8, 9, 5, 2, 0, 3, 7, 7, 2, 0, 6,\n",
      "        5, 0, 1, 8])\n",
      "Epoch [4/10], Step [500/600], Loss: 0.0115, Accuracy: 10.7100\n",
      "tensor([1, 5, 4, 3, 7, 3, 5, 0, 3, 6, 3, 2, 8, 6, 3, 4, 0, 0, 1, 8, 9, 5, 1, 5,\n",
      "        0, 9, 9, 4, 2, 6, 7, 0, 8, 2, 9, 3, 7, 2, 3, 6, 1, 5, 1, 2, 2, 0, 2, 7,\n",
      "        0, 9, 2, 1, 9, 0, 0, 3, 3, 7, 2, 7, 2, 8, 8, 5, 9, 9, 5, 1, 6, 5, 7, 1,\n",
      "        7, 8, 9, 9, 1, 9, 9, 8, 5, 0, 0, 1, 4, 5, 6, 1, 8, 1, 3, 9, 6, 7, 6, 2,\n",
      "        8, 2, 9, 1])\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0025, Accuracy: 10.8600\n",
      "tensor([1, 3, 2, 1, 3, 4, 4, 4, 3, 5, 1, 9, 8, 2, 0, 2, 6, 4, 1, 6, 7, 9, 5, 8,\n",
      "        3, 4, 2, 0, 1, 9, 6, 1, 6, 0, 8, 1, 9, 7, 7, 7, 2, 0, 6, 3, 4, 2, 8, 9,\n",
      "        2, 6, 1, 9, 0, 7, 8, 8, 4, 4, 1, 1, 0, 3, 2, 6, 7, 8, 2, 6, 6, 7, 6, 6,\n",
      "        6, 3, 2, 7, 9, 0, 5, 3, 5, 4, 3, 6, 3, 2, 5, 7, 1, 6, 8, 6, 1, 1, 8, 7,\n",
      "        7, 1, 2, 0])\n",
      "Epoch [5/10], Step [100/600], Loss: 0.0492, Accuracy: 10.3500\n",
      "tensor([3, 3, 6, 1, 7, 8, 5, 4, 2, 9, 7, 1, 9, 0, 9, 1, 5, 1, 4, 0, 2, 0, 2, 9,\n",
      "        5, 3, 2, 2, 5, 5, 6, 9, 2, 3, 2, 8, 4, 1, 7, 9, 8, 8, 6, 3, 2, 5, 7, 4,\n",
      "        5, 8, 2, 5, 9, 3, 8, 4, 4, 5, 5, 9, 1, 6, 0, 8, 5, 0, 6, 5, 7, 8, 1, 0,\n",
      "        0, 8, 7, 6, 2, 6, 6, 9, 2, 3, 0, 4, 3, 5, 1, 9, 4, 5, 2, 0, 2, 7, 3, 9,\n",
      "        3, 4, 7, 1])\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0110, Accuracy: 10.7400\n",
      "tensor([9, 1, 2, 4, 1, 6, 2, 1, 5, 7, 4, 9, 2, 8, 1, 5, 6, 6, 0, 9, 0, 1, 6, 4,\n",
      "        8, 1, 2, 3, 3, 4, 6, 6, 1, 7, 9, 9, 9, 8, 1, 9, 2, 5, 4, 8, 6, 0, 3, 7,\n",
      "        3, 5, 8, 6, 3, 9, 1, 2, 0, 6, 8, 1, 3, 3, 4, 1, 0, 5, 6, 9, 1, 2, 9, 3,\n",
      "        4, 7, 3, 3, 1, 5, 0, 0, 2, 8, 2, 2, 3, 4, 0, 7, 6, 4, 8, 4, 6, 9, 3, 5,\n",
      "        2, 1, 4, 3])\n",
      "Epoch [5/10], Step [300/600], Loss: 0.0736, Accuracy: 10.4900\n",
      "tensor([0, 6, 4, 7, 4, 3, 8, 6, 0, 5, 9, 1, 8, 8, 8, 1, 2, 3, 7, 3, 3, 5, 9, 6,\n",
      "        4, 6, 8, 3, 7, 9, 7, 5, 7, 2, 7, 3, 3, 5, 5, 1, 1, 7, 5, 2, 4, 3, 3, 2,\n",
      "        0, 4, 4, 3, 2, 0, 9, 1, 9, 0, 1, 4, 5, 7, 7, 1, 4, 7, 6, 0, 0, 8, 4, 8,\n",
      "        1, 3, 2, 7, 2, 7, 2, 4, 9, 8, 0, 5, 8, 9, 7, 8, 9, 2, 0, 3, 9, 2, 5, 1,\n",
      "        7, 3, 2, 1])\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0964, Accuracy: 11.3300\n",
      "tensor([1, 6, 8, 9, 1, 3, 6, 5, 8, 8, 2, 6, 3, 8, 1, 9, 3, 4, 2, 1, 3, 1, 1, 2,\n",
      "        9, 7, 3, 4, 8, 3, 0, 7, 5, 1, 3, 6, 4, 9, 7, 1, 3, 7, 1, 1, 4, 3, 8, 2,\n",
      "        9, 1, 8, 7, 1, 4, 9, 9, 9, 6, 9, 5, 7, 1, 0, 5, 3, 4, 5, 2, 7, 2, 0, 7,\n",
      "        3, 2, 7, 1, 5, 3, 3, 8, 9, 7, 9, 7, 5, 2, 1, 8, 6, 6, 0, 7, 1, 7, 4, 6,\n",
      "        4, 1, 5, 9])\n",
      "Epoch [5/10], Step [500/600], Loss: 0.0669, Accuracy: 10.7400\n",
      "tensor([9, 7, 4, 8, 1, 4, 6, 6, 7, 9, 3, 8, 2, 2, 6, 7, 1, 8, 2, 7, 8, 9, 8, 9,\n",
      "        7, 4, 0, 0, 9, 5, 7, 0, 3, 0, 4, 1, 3, 7, 0, 2, 2, 7, 1, 8, 6, 9, 6, 1,\n",
      "        6, 7, 9, 5, 6, 4, 1, 5, 9, 7, 7, 7, 2, 8, 4, 7, 1, 7, 9, 5, 0, 2, 6, 5,\n",
      "        0, 7, 4, 2, 1, 5, 9, 4, 6, 3, 9, 1, 6, 4, 9, 5, 2, 3, 0, 4, 6, 0, 0, 9,\n",
      "        2, 7, 1, 8])\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0009, Accuracy: 11.5800\n",
      "tensor([9, 2, 9, 4, 8, 9, 5, 4, 7, 3, 8, 8, 7, 1, 9, 9, 2, 8, 2, 6, 3, 0, 1, 1,\n",
      "        0, 8, 3, 1, 7, 8, 3, 0, 3, 1, 2, 1, 9, 0, 3, 2, 7, 8, 1, 8, 7, 7, 1, 4,\n",
      "        5, 8, 3, 0, 8, 2, 1, 7, 1, 2, 6, 8, 5, 1, 1, 6, 6, 6, 7, 0, 2, 6, 7, 6,\n",
      "        9, 0, 8, 1, 1, 0, 4, 3, 1, 3, 1, 6, 5, 1, 8, 7, 2, 7, 8, 9, 1, 9, 6, 2,\n",
      "        2, 2, 2, 4])\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0011, Accuracy: 10.9600\n",
      "tensor([6, 7, 5, 8, 3, 2, 5, 1, 5, 1, 9, 4, 1, 5, 2, 4, 7, 4, 1, 1, 3, 4, 7, 2,\n",
      "        4, 5, 2, 8, 0, 5, 4, 1, 8, 1, 0, 7, 3, 2, 8, 0, 1, 7, 7, 6, 3, 1, 0, 1,\n",
      "        2, 1, 6, 5, 9, 4, 0, 9, 9, 4, 2, 8, 2, 9, 1, 6, 3, 4, 3, 9, 0, 0, 0, 4,\n",
      "        9, 7, 1, 1, 2, 6, 2, 7, 3, 1, 5, 0, 2, 6, 1, 7, 5, 3, 6, 3, 5, 8, 3, 3,\n",
      "        1, 1, 9, 0])\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0434, Accuracy: 11.5200\n",
      "tensor([2, 3, 0, 0, 9, 3, 7, 7, 4, 8, 8, 1, 4, 1, 8, 7, 3, 4, 5, 8, 1, 1, 1, 7,\n",
      "        5, 9, 5, 9, 1, 6, 4, 3, 4, 2, 3, 6, 9, 5, 2, 4, 1, 2, 4, 0, 7, 5, 9, 3,\n",
      "        3, 0, 1, 9, 9, 7, 8, 5, 8, 3, 7, 8, 5, 7, 7, 9, 1, 2, 3, 7, 5, 1, 4, 1,\n",
      "        9, 3, 1, 4, 1, 7, 2, 1, 7, 4, 2, 7, 7, 4, 4, 1, 6, 5, 5, 3, 2, 4, 1, 6,\n",
      "        8, 7, 5, 8])\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0003, Accuracy: 10.5400\n",
      "tensor([5, 1, 0, 4, 4, 1, 3, 0, 0, 2, 2, 9, 2, 9, 5, 5, 8, 6, 7, 6, 5, 7, 1, 7,\n",
      "        6, 9, 1, 5, 3, 1, 2, 0, 2, 7, 9, 0, 4, 3, 6, 3, 0, 1, 8, 2, 1, 4, 8, 6,\n",
      "        6, 7, 8, 5, 0, 6, 6, 4, 7, 7, 4, 4, 3, 1, 4, 8, 4, 9, 3, 8, 5, 2, 3, 6,\n",
      "        6, 0, 8, 4, 6, 1, 6, 7, 9, 8, 8, 0, 2, 4, 6, 4, 6, 8, 2, 3, 7, 7, 6, 3,\n",
      "        5, 4, 5, 3])\n",
      "Epoch [6/10], Step [400/600], Loss: 0.1452, Accuracy: 11.3900\n",
      "tensor([6, 3, 7, 5, 6, 2, 1, 3, 8, 0, 2, 5, 3, 3, 6, 6, 6, 3, 1, 6, 6, 4, 7, 3,\n",
      "        4, 6, 8, 8, 7, 0, 7, 0, 7, 7, 8, 4, 2, 4, 5, 3, 7, 3, 9, 1, 6, 4, 7, 5,\n",
      "        2, 8, 0, 9, 1, 6, 9, 3, 2, 8, 6, 5, 4, 0, 5, 7, 1, 4, 9, 9, 2, 3, 6, 9,\n",
      "        9, 3, 0, 3, 9, 6, 8, 3, 9, 3, 0, 3, 3, 2, 9, 5, 7, 4, 6, 9, 1, 6, 6, 7,\n",
      "        3, 4, 5, 4])\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0085, Accuracy: 10.6800\n",
      "tensor([2, 5, 9, 5, 8, 9, 5, 4, 6, 7, 9, 3, 2, 1, 8, 4, 0, 4, 4, 4, 1, 3, 4, 4,\n",
      "        5, 9, 9, 2, 3, 3, 8, 6, 4, 1, 5, 9, 6, 0, 8, 8, 8, 7, 4, 0, 6, 1, 2, 1,\n",
      "        2, 1, 4, 1, 1, 9, 3, 5, 4, 5, 8, 9, 9, 7, 5, 5, 0, 3, 6, 9, 2, 7, 2, 7,\n",
      "        7, 7, 9, 0, 5, 2, 3, 9, 7, 0, 7, 5, 8, 3, 7, 5, 1, 3, 2, 1, 4, 6, 8, 2,\n",
      "        7, 9, 9, 9])\n",
      "Epoch [6/10], Step [600/600], Loss: 0.0142, Accuracy: 11.1000\n",
      "tensor([2, 9, 6, 3, 4, 0, 9, 4, 7, 7, 7, 6, 1, 2, 6, 7, 1, 5, 6, 7, 5, 2, 4, 2,\n",
      "        0, 8, 3, 1, 0, 7, 8, 5, 3, 7, 7, 4, 7, 4, 7, 8, 3, 2, 5, 9, 6, 2, 7, 0,\n",
      "        7, 1, 2, 6, 7, 2, 2, 4, 9, 4, 4, 8, 8, 9, 2, 0, 1, 6, 1, 8, 1, 3, 2, 3,\n",
      "        8, 0, 7, 4, 3, 5, 7, 8, 2, 4, 0, 3, 5, 8, 3, 4, 8, 4, 7, 4, 3, 7, 8, 5,\n",
      "        2, 0, 5, 9])\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0247, Accuracy: 11.6100\n",
      "tensor([7, 7, 0, 1, 0, 3, 0, 4, 0, 3, 3, 2, 1, 2, 7, 9, 8, 7, 7, 0, 6, 3, 9, 1,\n",
      "        8, 8, 9, 0, 1, 3, 9, 7, 0, 3, 3, 6, 4, 6, 3, 4, 6, 7, 5, 0, 4, 3, 2, 5,\n",
      "        7, 0, 4, 3, 3, 1, 6, 6, 4, 0, 7, 0, 9, 5, 3, 6, 1, 1, 7, 0, 9, 6, 2, 8,\n",
      "        8, 1, 8, 9, 0, 3, 7, 2, 5, 5, 0, 0, 2, 8, 0, 8, 1, 7, 1, 1, 7, 5, 3, 3,\n",
      "        0, 8, 0, 4])\n",
      "Epoch [7/10], Step [200/600], Loss: 0.0284, Accuracy: 10.5300\n",
      "tensor([3, 1, 5, 9, 0, 2, 9, 3, 1, 2, 4, 7, 9, 2, 9, 4, 6, 4, 1, 5, 9, 4, 6, 8,\n",
      "        7, 4, 0, 0, 9, 5, 1, 6, 7, 3, 0, 7, 7, 1, 7, 8, 4, 2, 4, 6, 6, 6, 3, 2,\n",
      "        9, 6, 4, 5, 2, 7, 2, 3, 2, 4, 5, 3, 0, 1, 6, 8, 6, 0, 8, 8, 4, 9, 4, 4,\n",
      "        5, 9, 4, 8, 7, 8, 3, 8, 6, 0, 9, 0, 7, 7, 0, 6, 3, 4, 8, 2, 4, 0, 5, 0,\n",
      "        3, 2, 5, 3])\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0024, Accuracy: 10.8600\n",
      "tensor([3, 7, 0, 9, 7, 1, 8, 2, 6, 7, 7, 0, 7, 1, 0, 3, 2, 5, 6, 8, 1, 3, 8, 3,\n",
      "        5, 9, 3, 4, 6, 7, 8, 6, 6, 9, 5, 3, 6, 4, 0, 2, 4, 8, 1, 4, 2, 6, 2, 4,\n",
      "        9, 6, 4, 8, 6, 6, 9, 8, 1, 3, 9, 2, 9, 3, 5, 3, 0, 9, 5, 8, 6, 3, 2, 9,\n",
      "        2, 8, 4, 9, 5, 3, 4, 5, 1, 0, 3, 9, 1, 6, 8, 7, 6, 1, 1, 0, 6, 8, 3, 9,\n",
      "        9, 1, 6, 9])\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0558, Accuracy: 11.3800\n",
      "tensor([8, 9, 3, 1, 6, 4, 8, 0, 1, 0, 0, 1, 4, 9, 1, 6, 0, 0, 9, 3, 8, 6, 5, 7,\n",
      "        2, 8, 4, 3, 4, 1, 4, 2, 1, 5, 6, 3, 4, 9, 7, 7, 9, 3, 1, 6, 3, 6, 8, 6,\n",
      "        1, 9, 6, 4, 6, 6, 7, 2, 5, 6, 3, 5, 0, 5, 1, 2, 3, 3, 5, 8, 6, 0, 5, 6,\n",
      "        9, 4, 6, 1, 2, 1, 3, 1, 5, 6, 8, 1, 0, 9, 1, 0, 9, 3, 1, 9, 8, 6, 0, 9,\n",
      "        0, 6, 2, 2])\n",
      "Epoch [7/10], Step [500/600], Loss: 0.1465, Accuracy: 11.3300\n",
      "tensor([5, 0, 5, 4, 6, 4, 3, 9, 1, 2, 9, 4, 5, 5, 3, 0, 2, 1, 9, 6, 1, 0, 4, 4,\n",
      "        6, 6, 2, 2, 7, 7, 7, 2, 2, 6, 4, 8, 6, 9, 8, 8, 7, 0, 2, 9, 5, 7, 5, 5,\n",
      "        0, 8, 4, 1, 1, 9, 3, 2, 2, 2, 1, 2, 0, 1, 9, 5, 1, 4, 8, 0, 0, 0, 4, 5,\n",
      "        1, 7, 2, 1, 0, 1, 6, 4, 2, 0, 8, 1, 7, 4, 0, 0, 4, 7, 7, 5, 2, 9, 5, 1,\n",
      "        5, 0, 0, 2])\n",
      "Epoch [7/10], Step [600/600], Loss: 0.0007, Accuracy: 10.5400\n",
      "tensor([7, 3, 6, 9, 3, 0, 5, 0, 9, 3, 2, 6, 8, 7, 6, 9, 2, 7, 1, 7, 2, 8, 1, 4,\n",
      "        9, 8, 1, 4, 9, 2, 9, 3, 9, 1, 9, 8, 6, 1, 6, 0, 2, 8, 4, 1, 2, 3, 5, 7,\n",
      "        9, 0, 0, 0, 5, 4, 8, 8, 6, 3, 0, 1, 0, 7, 7, 5, 5, 9, 6, 1, 4, 9, 3, 2,\n",
      "        8, 8, 9, 4, 6, 6, 5, 2, 5, 3, 3, 8, 7, 7, 9, 5, 6, 3, 5, 3, 9, 3, 0, 0,\n",
      "        2, 9, 0, 6])\n",
      "Epoch [8/10], Step [100/600], Loss: 0.0138, Accuracy: 11.5300\n",
      "tensor([3, 9, 1, 0, 8, 4, 7, 0, 2, 9, 7, 8, 1, 6, 1, 9, 3, 2, 6, 4, 0, 8, 7, 1,\n",
      "        3, 9, 0, 7, 7, 1, 5, 7, 9, 5, 6, 9, 8, 4, 6, 6, 6, 8, 0, 9, 0, 1, 0, 8,\n",
      "        8, 4, 0, 0, 3, 8, 6, 0, 2, 0, 1, 3, 7, 9, 1, 7, 1, 2, 0, 5, 6, 8, 1, 6,\n",
      "        0, 7, 7, 7, 6, 8, 3, 6, 5, 7, 8, 7, 1, 7, 9, 9, 7, 4, 1, 2, 1, 1, 5, 3,\n",
      "        9, 2, 1, 0])\n",
      "Epoch [8/10], Step [200/600], Loss: 0.0228, Accuracy: 10.4200\n",
      "tensor([7, 0, 6, 2, 1, 6, 4, 1, 1, 5, 2, 4, 5, 6, 3, 9, 9, 0, 5, 6, 9, 5, 8, 5,\n",
      "        5, 6, 2, 8, 1, 8, 6, 6, 8, 7, 4, 4, 9, 8, 7, 4, 9, 3, 9, 9, 0, 4, 4, 5,\n",
      "        6, 7, 7, 7, 7, 9, 7, 2, 5, 9, 0, 1, 8, 0, 6, 8, 8, 0, 1, 0, 0, 9, 4, 0,\n",
      "        7, 4, 7, 0, 2, 3, 1, 2, 8, 8, 2, 5, 3, 1, 6, 8, 0, 2, 9, 7, 5, 1, 6, 2,\n",
      "        9, 3, 0, 5])\n",
      "Epoch [8/10], Step [300/600], Loss: 0.0280, Accuracy: 12.2400\n",
      "tensor([2, 2, 2, 2, 0, 2, 4, 2, 3, 1, 7, 3, 4, 7, 4, 2, 3, 1, 2, 9, 8, 0, 4, 8,\n",
      "        6, 1, 9, 0, 2, 9, 1, 5, 5, 9, 9, 1, 2, 9, 6, 0, 9, 8, 9, 7, 8, 9, 2, 6,\n",
      "        5, 9, 3, 0, 6, 7, 9, 0, 3, 4, 8, 6, 5, 6, 7, 1, 7, 3, 8, 2, 2, 0, 2, 7,\n",
      "        9, 5, 7, 4, 4, 2, 9, 0, 2, 2, 5, 2, 6, 4, 1, 1, 6, 5, 2, 3, 2, 9, 2, 1,\n",
      "        2, 1, 5, 2])\n",
      "Epoch [8/10], Step [400/600], Loss: 0.0861, Accuracy: 10.4500\n",
      "tensor([0, 0, 1, 5, 8, 7, 8, 4, 5, 7, 8, 9, 7, 5, 3, 9, 6, 6, 3, 8, 7, 2, 7, 5,\n",
      "        6, 7, 0, 3, 1, 2, 7, 4, 4, 9, 9, 6, 9, 1, 7, 7, 0, 0, 6, 2, 9, 4, 9, 5,\n",
      "        6, 4, 5, 3, 4, 1, 6, 7, 0, 4, 9, 2, 9, 4, 5, 1, 0, 1, 3, 3, 8, 4, 9, 3,\n",
      "        4, 0, 7, 0, 2, 7, 2, 1, 3, 9, 5, 8, 7, 6, 3, 5, 5, 9, 0, 1, 4, 2, 8, 7,\n",
      "        6, 6, 9, 5])\n",
      "Epoch [8/10], Step [500/600], Loss: 0.0059, Accuracy: 11.1000\n",
      "tensor([8, 1, 1, 9, 2, 3, 9, 3, 3, 4, 9, 6, 7, 5, 3, 3, 9, 5, 1, 6, 3, 2, 0, 0,\n",
      "        3, 8, 6, 8, 6, 9, 6, 6, 9, 8, 7, 2, 3, 2, 2, 7, 8, 6, 8, 1, 3, 0, 3, 0,\n",
      "        0, 9, 5, 5, 6, 4, 3, 4, 2, 0, 6, 4, 2, 9, 0, 0, 1, 4, 1, 9, 1, 4, 3, 9,\n",
      "        7, 5, 0, 6, 2, 0, 3, 7, 5, 0, 8, 1, 4, 3, 5, 9, 3, 5, 5, 0, 3, 3, 4, 1,\n",
      "        2, 5, 6, 3])\n",
      "Epoch [8/10], Step [600/600], Loss: 0.0137, Accuracy: 11.9700\n",
      "tensor([2, 1, 9, 2, 9, 8, 7, 7, 2, 9, 3, 8, 9, 6, 9, 9, 9, 0, 4, 2, 8, 4, 1, 4,\n",
      "        6, 2, 3, 6, 0, 6, 9, 8, 6, 1, 0, 7, 4, 2, 2, 9, 4, 1, 7, 0, 8, 1, 0, 9,\n",
      "        4, 6, 8, 7, 3, 8, 0, 8, 9, 0, 4, 9, 6, 1, 9, 4, 4, 1, 9, 8, 9, 1, 5, 1,\n",
      "        1, 7, 5, 1, 2, 7, 6, 4, 9, 7, 9, 7, 1, 1, 4, 8, 1, 9, 6, 2, 2, 9, 3, 7,\n",
      "        4, 3, 0, 7])\n",
      "Epoch [9/10], Step [100/600], Loss: 0.1293, Accuracy: 10.7900\n",
      "tensor([2, 5, 1, 6, 9, 5, 3, 3, 7, 1, 1, 9, 6, 9, 4, 7, 6, 4, 4, 9, 4, 5, 2, 3,\n",
      "        5, 9, 6, 5, 0, 1, 4, 2, 3, 6, 8, 9, 4, 0, 6, 1, 9, 7, 2, 4, 0, 8, 9, 3,\n",
      "        2, 7, 4, 7, 4, 4, 6, 5, 2, 2, 5, 8, 0, 0, 8, 5, 1, 7, 0, 8, 0, 1, 4, 8,\n",
      "        7, 4, 3, 8, 4, 3, 6, 4, 6, 4, 4, 8, 3, 3, 8, 1, 6, 8, 3, 2, 4, 6, 6, 8,\n",
      "        7, 2, 1, 9])\n",
      "Epoch [9/10], Step [200/600], Loss: 0.0015, Accuracy: 10.8800\n",
      "tensor([2, 7, 9, 3, 7, 7, 6, 3, 6, 1, 4, 2, 2, 3, 5, 7, 9, 0, 9, 2, 3, 7, 2, 1,\n",
      "        6, 7, 3, 4, 0, 7, 2, 3, 7, 8, 2, 0, 7, 3, 4, 2, 3, 6, 9, 4, 0, 6, 7, 9,\n",
      "        2, 6, 8, 4, 9, 3, 8, 4, 7, 0, 9, 3, 6, 4, 6, 0, 5, 8, 8, 0, 9, 2, 6, 8,\n",
      "        0, 5, 1, 9, 6, 5, 0, 6, 8, 9, 9, 3, 4, 5, 8, 3, 6, 3, 7, 7, 2, 4, 7, 8,\n",
      "        1, 4, 5, 2])\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0376, Accuracy: 11.1100\n",
      "tensor([1, 2, 1, 1, 1, 1, 4, 6, 7, 8, 2, 1, 4, 9, 2, 6, 8, 4, 3, 1, 8, 4, 6, 4,\n",
      "        1, 0, 4, 5, 8, 9, 8, 9, 1, 1, 2, 5, 8, 8, 7, 8, 2, 1, 3, 8, 8, 3, 5, 1,\n",
      "        1, 7, 3, 4, 8, 7, 3, 7, 4, 0, 6, 3, 6, 5, 9, 3, 1, 8, 1, 6, 3, 9, 3, 0,\n",
      "        4, 7, 1, 6, 7, 8, 2, 2, 0, 6, 2, 9, 4, 0, 0, 5, 3, 7, 7, 9, 0, 7, 5, 3,\n",
      "        1, 3, 7, 8])\n",
      "Epoch [9/10], Step [400/600], Loss: 0.0457, Accuracy: 10.4900\n",
      "tensor([1, 0, 9, 1, 6, 1, 2, 6, 3, 8, 7, 6, 0, 6, 0, 2, 7, 5, 7, 2, 4, 2, 8, 8,\n",
      "        1, 8, 7, 3, 1, 9, 8, 7, 5, 6, 7, 5, 2, 4, 4, 5, 8, 6, 1, 4, 9, 8, 0, 7,\n",
      "        1, 6, 6, 0, 6, 9, 0, 9, 8, 5, 2, 7, 4, 9, 3, 8, 5, 0, 5, 0, 0, 2, 2, 5,\n",
      "        4, 4, 5, 3, 2, 9, 6, 5, 9, 2, 7, 9, 0, 8, 6, 0, 5, 0, 2, 5, 7, 1, 3, 1,\n",
      "        6, 1, 0, 8])\n",
      "Epoch [9/10], Step [500/600], Loss: 0.0563, Accuracy: 10.6200\n",
      "tensor([0, 1, 4, 6, 0, 1, 8, 6, 7, 6, 4, 6, 7, 5, 8, 1, 7, 8, 2, 2, 3, 8, 5, 4,\n",
      "        7, 8, 7, 7, 9, 1, 3, 9, 7, 5, 0, 1, 4, 8, 0, 1, 6, 1, 8, 9, 7, 9, 8, 3,\n",
      "        8, 3, 6, 0, 4, 9, 9, 1, 8, 3, 0, 8, 6, 5, 6, 5, 1, 4, 4, 1, 1, 5, 9, 3,\n",
      "        2, 2, 3, 5, 0, 5, 8, 3, 1, 7, 3, 9, 3, 8, 1, 2, 4, 0, 6, 0, 1, 5, 2, 0,\n",
      "        7, 0, 3, 8])\n",
      "Epoch [9/10], Step [600/600], Loss: 0.1087, Accuracy: 10.5900\n",
      "tensor([3, 8, 7, 4, 7, 2, 3, 9, 8, 0, 3, 4, 6, 2, 0, 4, 6, 2, 7, 2, 5, 0, 6, 6,\n",
      "        3, 8, 9, 2, 9, 0, 9, 8, 8, 9, 1, 8, 5, 1, 7, 8, 1, 2, 8, 7, 0, 1, 6, 1,\n",
      "        0, 6, 2, 3, 0, 3, 5, 6, 5, 9, 1, 7, 0, 8, 6, 3, 9, 4, 3, 3, 7, 8, 8, 2,\n",
      "        7, 7, 3, 6, 1, 2, 7, 4, 0, 0, 7, 1, 2, 2, 7, 1, 9, 2, 7, 9, 9, 1, 5, 8,\n",
      "        4, 2, 4, 6])\n",
      "Epoch [10/10], Step [100/600], Loss: 0.0624, Accuracy: 10.3500\n",
      "tensor([5, 3, 9, 3, 9, 9, 8, 0, 9, 2, 0, 2, 5, 9, 6, 4, 1, 6, 8, 9, 7, 1, 7, 9,\n",
      "        4, 0, 3, 7, 4, 7, 9, 1, 7, 6, 2, 1, 0, 2, 1, 3, 9, 3, 1, 5, 8, 5, 3, 7,\n",
      "        5, 8, 0, 1, 9, 1, 1, 9, 5, 4, 4, 3, 5, 4, 9, 3, 2, 2, 4, 0, 6, 3, 4, 1,\n",
      "        2, 2, 8, 6, 2, 0, 7, 1, 7, 8, 3, 3, 5, 2, 6, 7, 8, 8, 8, 8, 6, 0, 4, 2,\n",
      "        3, 5, 9, 7])\n",
      "Epoch [10/10], Step [200/600], Loss: 0.0227, Accuracy: 11.7000\n",
      "tensor([7, 6, 0, 9, 9, 2, 7, 6, 8, 8, 6, 1, 5, 6, 5, 5, 9, 9, 4, 9, 9, 0, 5, 0,\n",
      "        5, 3, 6, 5, 3, 8, 7, 4, 0, 9, 4, 0, 3, 9, 4, 3, 9, 9, 8, 3, 8, 0, 6, 7,\n",
      "        6, 9, 9, 0, 3, 1, 8, 9, 6, 4, 4, 1, 3, 9, 7, 1, 9, 0, 4, 7, 6, 2, 9, 7,\n",
      "        8, 2, 6, 9, 8, 8, 9, 9, 4, 3, 7, 1, 1, 1, 1, 7, 8, 8, 1, 9, 4, 1, 1, 8,\n",
      "        6, 8, 5, 3])\n",
      "Epoch [10/10], Step [300/600], Loss: 0.0730, Accuracy: 10.9600\n",
      "tensor([1, 8, 7, 2, 0, 9, 9, 9, 2, 1, 8, 1, 1, 0, 1, 1, 3, 3, 0, 5, 8, 8, 5, 6,\n",
      "        6, 1, 1, 8, 9, 0, 1, 4, 8, 7, 9, 8, 4, 5, 6, 1, 3, 2, 6, 4, 6, 4, 1, 7,\n",
      "        1, 6, 3, 0, 6, 3, 4, 0, 2, 8, 7, 1, 8, 2, 7, 9, 4, 9, 2, 7, 2, 8, 0, 6,\n",
      "        5, 1, 7, 3, 6, 9, 4, 3, 1, 0, 6, 5, 0, 7, 8, 8, 5, 7, 9, 7, 1, 1, 6, 6,\n",
      "        9, 5, 9, 0])\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0142, Accuracy: 10.7800\n",
      "tensor([7, 9, 7, 0, 7, 3, 6, 5, 8, 3, 3, 7, 7, 6, 8, 2, 6, 9, 7, 5, 6, 0, 0, 2,\n",
      "        2, 7, 9, 3, 6, 2, 6, 5, 0, 7, 3, 8, 0, 4, 6, 9, 3, 9, 3, 8, 8, 5, 9, 0,\n",
      "        1, 6, 4, 3, 0, 2, 7, 1, 8, 7, 8, 6, 5, 9, 7, 7, 4, 6, 4, 6, 9, 6, 4, 0,\n",
      "        3, 5, 9, 9, 1, 5, 6, 5, 3, 5, 4, 4, 2, 8, 0, 8, 3, 6, 9, 0, 7, 1, 1, 8,\n",
      "        7, 8, 2, 7])\n",
      "Epoch [10/10], Step [500/600], Loss: 0.0278, Accuracy: 11.4200\n",
      "tensor([2, 3, 2, 9, 2, 5, 3, 8, 7, 6, 9, 0, 1, 1, 3, 1, 2, 6, 7, 2, 7, 6, 2, 9,\n",
      "        7, 7, 0, 6, 9, 1, 3, 3, 5, 2, 0, 9, 0, 7, 1, 3, 5, 3, 8, 4, 4, 1, 1, 3,\n",
      "        6, 5, 0, 5, 0, 2, 1, 4, 2, 5, 3, 7, 3, 1, 0, 5, 3, 4, 7, 0, 3, 7, 3, 0,\n",
      "        7, 3, 3, 2, 4, 6, 7, 1, 5, 7, 0, 5, 3, 0, 0, 9, 5, 0, 4, 2, 6, 6, 5, 5,\n",
      "        6, 8, 7, 1])\n",
      "Epoch [10/10], Step [600/600], Loss: 0.0582, Accuracy: 10.6700\n",
      "tensor([6, 9, 4, 5, 8, 3, 6, 5, 7, 9, 8, 9, 3, 7, 9, 6, 3, 9, 5, 4, 1, 1, 3, 2,\n",
      "        1, 8, 1, 3, 7, 7, 0, 0, 8, 8, 1, 5, 0, 4, 2, 1, 4, 0, 1, 1, 5, 7, 7, 0,\n",
      "        4, 5, 9, 4, 0, 8, 7, 0, 4, 3, 5, 1, 1, 7, 6, 9, 9, 2, 0, 2, 8, 2, 8, 5,\n",
      "        7, 5, 5, 1, 7, 8, 5, 6, 1, 8, 3, 5, 8, 6, 0, 0, 3, 7, 0, 7, 0, 8, 5, 8,\n",
      "        2, 6, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "loaders = {\n",
    "    'train' : trainloader,\n",
    "    \n",
    "    'test'  : testloader,\n",
    "}\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "def getaccuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        total, correct = 0,0\n",
    "  \n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels.squeeze(1))   # batch y\n",
    "            # print(b_x)\n",
    "            output = cnn(b_x)[0]  \n",
    "            # print(output.shape) \n",
    "            # print(b_y.shape)            \n",
    "            loss = criterion(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()            \n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += math.floor(labels.size(0) * torch.mean(torch.eq(predicted,labels).float()))\n",
    "            # accuracy = torch.mean(torch.eq(predicted,labels).float())\n",
    "            accuracy = getaccuracy(output,labels)\n",
    " \n",
    "            if (i+1) % 100 == 0:\n",
    "                # accuracy = 100 *correct / total\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),accuracy))\n",
    "                print(predicted)\n",
    "                pass\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    pass\n",
    "# train(num_epochs, predictionModel, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# generate graphs\n",
    "model.graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test the model\n",
    "total = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "for data in testloader:\n",
    "    # get the data\n",
    "    inputs = data[0]\n",
    "    labels = data[1]\n",
    "\n",
    "    # make predictions\n",
    "    output = predictionModel(inputs)[0]\n",
    "\n",
    "    # accuracy =getaccuracy(output,labels)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 *correct /total\n",
    "    # print ('Accuracy: {:.4f}'.format(accuracy))\n",
    "\n",
    "\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: ./images/handwritten_four.jpg \n",
      "Prediction: tensor([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAlUlEQVR4nMWQMQoCUQxEX76uv14bLfQigsXexUt4JE8gYuMptBVFbLVzYSGWG/EnpU6V8BhmEvi7ROyW+vEMDFeOawfIyXFWADcpwwzgZU4B6bQI0x7QXO4zGIOkrb2mnzbz+tHm0Ut1+e2cLGZZ5JI+/2Ald9PQtgXQJz7koPhq3EQgrQNYHYPMrg6gXCMYFSKEP9AbJEEYDVsHgHIAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: ./images/handwritten_six.png \n",
      "Prediction: tensor([6])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhklEQVR4nNWQsQ0CMRAEhxfSF0ADZJRCQhsv6ICAPuiEGqiBFogJ/pHQEPCBbd0RIrGRfeO9XRl+otsX9nAqbouKCXaJ76XbbOdB+zRQj/WgyLRtQJe8bKBc2pxlcV4ZuAEYnRVX1Q2s3YUQgCG0zsOK1T95DRPh5PmZ9fk08h4z0H2G/l9vw645r8RJxhYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: ./images/handwritten_three.png \n",
      "Prediction: tensor([3])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgoAPg1JRF5jIimP8xhWDA6v///98ZGBgY/v/HkPv8//8DqAEYkrL//8NMw6ITLvQXiyQMvEeWQ3PafxQRFjQpBg4kPiO6JFZ/woDa/9u4JZG9woRHGYmSc/AozsAaQP8ZGBgYZP7//2+DEGNEkWRgYGD9g83Avf//36/G57zBDgBeky3Jz3Y9FAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# read list of test images\n",
    "folder = './images/'\n",
    "img_list =  os.listdir(folder)\n",
    "\n",
    "# predict for each file\n",
    "for image in img_list:\n",
    "    file_path = folder + image\n",
    "\n",
    "    test_image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # format Image\n",
    "    img_resized = cv2.resize(test_image, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # convert test image to tensor for prediction\n",
    "    tensor_img = torch.from_numpy(~img_resized)\n",
    "    reshaped_img = np.reshape(tensor_img, [1,1,28,28])\n",
    " \n",
    "    # make predictions\n",
    "    output = predictionModel(reshaped_img)[0]\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    print(f\"\\nImage: {file_path} \\nPrediction: {predicted}\")\n",
    "\n",
    "    # squeeze 1 dimension\n",
    "    reshaped_img = reshaped_img.squeeze()\n",
    "    numImage = Image.fromarray((reshaped_img.numpy()))\n",
    "\n",
    "    display(numImage)\n",
    "\n",
    "# Note the testing did not work on images that were not inverted\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb5d223395ffa13ce0bb8900d854bb07b9948fb92b9110105edc4f288e135ea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
